文章编号：1000- 6893 200004- 035- 03

# 基于神经网络预测模型的歼击机结构故障检测方法

胡寿松，汪晨曦（南京航空航天大学自动控制系，江苏南京 210016）STRUCTUREFAULTDETECTIONBASEDONNEURALNETWORKPREDICTIONMODELFORAFIGHTERHU Shou- song,WANG Chen- xiDepartment of Auwnture Control,Anjing Unw. of Aero. and A sub.;,Anjing 210016,China)

摘要：提出了一种基于预测神经网络的歼击机结构故障检测新方法，与传统的基于模型的非线性系统的故障检测方法相比，神经网络方法有着非线性逼近能力强和故障检测实时性好等优点给出了基于预测神经网络的故障检测方案，以及多步直接预测算法和阈值选取原则，最后以某型歼击机为例进行了仿真验证，仿真结果表明本方法能有效地检测出歼击机的各种结构故障

关键词：预测神经网络；故障检测；阈值

中图分类号：V249.1.21 文献标识码：A

Ab stract This paper describes the app lca tion of n eura lnetw orks for structure f alure dete ction for a figh ter. As com pare d w ith tra ditio nal m o del- based fail ue detection for n on lin ear system s,neu al ne w ork me thod s h ave the ad van tag es of stro ng n on lin ear ap pro xim ation ability and fast de te ction A pred ction n eu m lne w ork sch em e for fau lt dete ction has been dev eb ped，a bng w ith m u tiple step d rect pred ction ag orithm and thresh old sele ction p rincip le in this paper. Fin ally, the prop osed sch em e is dem onstrated usin g the m o del of a figh ter and the reus lts show that the neu ral netw ork m ethod is an effectiv e too lfor stru cture fau lt dete ction of a figh ter.

Key words: prediction- neural netw ork; failure detection; threshold

结构故障诊断通常包括故障检测和故障隔离2个过程，前者简单地作二值判断：系统正常或者发生故障；后者则进一步寻找故障来源，有些时候还需要鉴别故障的类型和性质本文提出了一种基于神经网络预测模型的歼击机结构故障检测方案，其思想来源于非线性系统辨识方法

# 1 基于神经网络的故障检测原理

对于复杂的不确定系统，神经网络的结构一般按经验和跟踪误差来确定，网络的权值在训练过程中确定，以使得模型误差  $\mathrm{y}(\mathrm{k}) - \mathrm{y}(\mathrm{k})$  [1]达到最小神经网络故障检测原理如图1所示

本文提出的时间序列多步直接预测神经网络是一种在分类能力和学习速度等方面均优于BP网络的径向基函数网络（RBF），网络结构如图2所示其输入可分为2个部分：时间序列的历史数据及影响时间序列取值的主要变量的当前取值其中时间序列的历史数据通过时延环节进入网

表情日期：1999- 04- 13：修订日期：1999- 11- 10基金项目：国家自然科学基金及航空科学基金资助项目文章网址：http：增www.hkxb.net.cn增kxb效000增4增355增

络，作为网络的第1部分输入时间序列的历史数据进入网络后通过相应的学习算法来调整网络参数，使得预测值y逼近实际值y

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/5e1ff204-713d-4689-a2f7-dde4798d729f/49487cade236ccbb06922ceaeba053e78e7346bb13e920ed02cf5861058db870.jpg)  
图1 故障诊断原理框图

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/5e1ff204-713d-4689-a2f7-dde4798d729f/bd338489f5c692e3239c340069a1b25125932b8676d66567bc9679e79dba9b31.jpg)  
图2 神经网络预测模型

一个非线性动力学系统可以分解为一个线性动力学系统和一些非线性环节前者可以用前馈神经网络实现，后者则相当于时延环节假设一非线性动力学系统描述为

$$
\mathrm{y}(\mathrm{k}) = \mathrm{F}[\mathrm{y}(\mathrm{k} - 1),\& ,\mathrm{y}(\mathrm{k} - \mathrm{m}),
$$

$$
\mathrm{u}(\mathrm{k}),\& ,\mathrm{u}(\mathrm{k} - \mathrm{n})
$$

其中：u为输入向量；y为输出向量  $\# \mathrm{H}$  （·）表示一非线性函数那么带有权阵  $\mathbb{W}$  的前馈神经网络就可用来表示这个非线性系统，其输出为

$$
\mathrm{y}(\mathrm{k}) = \mathrm{NN} \mathbb{W}, \mathrm{y}(\mathrm{k} - 1), \& , \mathrm{y}(\mathrm{k} - \mathrm{m}),
$$

$$
\mathrm{u}(\mathrm{k}),\& ,\mathrm{u}(\mathrm{k} - \mathrm{n})
$$

预测模型神经网采取合适的学习规则可以由飞机过去的飞行数据在线记忆系统的性质特征，自动调节权值W使得  $\mathrm{y}(\mathrm{k}) - \mathrm{y}(\mathrm{k})$  达到最小，从而逼近飞机模型，得到所谓的一步预测模型y该神经网络用来记忆飞机正常时的特性，以便下一步生成残差

# 2神经网络模型的时间序列直接多步预测算法

残差对应着系统输出的实际值和期望值的偏差期望的系统响应是利用神经网络预测模型来实现的，实际值与期望值的差值定义为残差向量

$$
\mathrm{r}(\mathrm{k}) = \mathrm{y}(\mathrm{k}) - \mathrm{y}(\mathrm{k})
$$

残差  $\mathrm{r}(\mathrm{k})$  应该不依赖于系统的工作点无故障时，残差的生成仅仅是由于噪声和干扰引起的；一旦有故障发生，残差应该以特定的方式偏离零位

RBF网络为3层信息处理结构：第1层为直接输入层；隐层由若干节点组成，每个节点包含一个中心  $\mathbb{C}$  ，算出网络输入向量与中心之间的欧氏距离，然后经一非线性映射  $\mathbb{K}(\bullet)$  传递到输出单元；网络的输出为隐单元输出的线性组合因此整个RBF神经网络的输入输出特性为非线性映射 $\mathrm{f}:\mathrm{R}^{\mathrm{n}}\rightarrow \mathrm{R}^{\mathrm{m}}$  ，即

$\mathrm{f}_{\mathrm{i}}\mathrm{~\AA~}) = \mathrm{~\Lambda~}_{\mathrm{j} = 1}\mathrm{~w~}_{\mathrm{j}}$  疏（  $\mathrm{x - c_{j}}$  ，  $\mathrm{~\AA~})_{\mathrm{~i~}} = \mathrm{~1~},2,\& \mathrm{~,~m~}$  式中：  $\mathrm{n} = \mathrm{m}\times \mathrm{n}_{\mathrm{y}} + \mathrm{r}\times \mathrm{n}_{\mathrm{u}}$  为输入节点个数；  $\mathrm{~s~},\mathrm{~m~}$  分别为隐层和输出节点数；  $\mathrm{w}_{\mathrm{ji}}$  为输出层线性组合的权重；·表示欧氏范数；宽度  $\mathrm{~\AA~}$  为一正标量； $\mathrm{f}_{\mathrm{6}}$  狄表示  $\mathrm{R}^{+}\rightarrow \mathrm{R}$  的非线性函数通常  $\mathrm{f}(\bullet)$  可选为正态分布的高斯函数：  $\mathrm{f}_{\mathrm{L}}^{\prime},\mathrm{f}_{\mathrm{L}}^{\prime} = \mathrm{exp}(- \mathrm{z}^{2}$  焕独

通常网络输入数据仅存在于输入空间  $\mathbb{R}^{\mathrm{n}}$  的某些区域，因此可在这些区域合理地选取RBF中心来反映数据的模式特征由于RBF网络的响应与权值之间呈线性关系，故可采用最小二乘法

（S）来调整权向量本文首先通过无监督的聚类算法来调整RBF网络的中心，然后利用有监督的LS法来更新权值以产生期望的特性，其具体过程为：隐层神经元模型取为

$$
\begin{array}{r}\mathrm{~z~}_{\mathrm{i}} = \mathrm{~f~}_{\mathrm{~j~} = 1}^{\mathrm{~N~}}\mathrm{~\mathfrak{z}~}_{\mathrm{i}} - \mathrm{~c~}_{\mathrm{ij}})^{2} \end{array}
$$

对于第s个输入样本  $\mathrm{X}_{\mathrm{s}}$  ，第i个隐节点的输出为 $\mathrm{z_{is} = \frac{1}{\hbar}\left(\mathrm{~X_{s}~} - \mathrm{~c_{i}~}\right) = \exp\mathrm{~ - ~\frac{1}{\hbar}~}\left(\mathrm{~\mathfrak{z}_{i}~} - \mathrm{~c_{ij}~}\right)^{2}}$  式中：  $\mathrm{c}_{\mathrm{i}}$  表示径向对称函数  $\#$  的中心；  $\mathbf{f}_{\mathrm{ij}}$  为样本协方差矩阵中的元；  $\mathbf{c}_{\mathrm{ij}}$  为中心

第i个输出节点的输出表达式为

$$
\mathrm{y}_{\mathrm{i}} = \mathrm{\Lambda}_{\mathrm{j} = 0}^{\mathrm{L}}\mathrm{w}_{\mathrm{ij}}\mathrm{z}_{\mathrm{ij}} = \mathrm{Z}\mathrm{\Lambda}\mathrm{f})\mathrm{W}_{\mathrm{i}}^{\mathrm{T}}\mathrm{\Lambda}\mathrm{f})
$$

定义误差评价准则函数

$$
\begin{array}{r}\mathrm{~E~}\mathfrak{A})=\frac{1}{2}\underset{\mathrm{~k=1~}}{\overset{\mathrm{~n~}}{\mathrm{~\psi~}}}\underset{\mathrm{~i=1~}}{\overset{\mathrm{~M~}}{\mathrm{~\psi~}}}\underset{\mathrm{~\psi~}}{\overset{\mathrm{~M~}}{\mathrm{~\psi~}}}\underset{\mathrm{~\psi~}}{\overset{\mathrm{~M~}}{\mathrm{~\psi~}}}\underset{\mathrm{~\psi~}}{\overset{\mathrm{~M~}}{\mathrm{~\psi~}}}\underset{\mathrm{~\psi~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\psi~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\psi~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\psi~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\psi~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M~}}{}}\mathrm{~\psi~}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~M~}~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M~}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M}}{}}\underset{\mathrm{~\mathrm{~\psi~}~}}{\overset{\mathrm{~M}}{}}\underset{\mathrm{~\mathrm{~\mathrm{~\psi~}~}}}{\overset{\mathrm{~M}}{}}\underset{\mathrm{~\mathrm{~\mathrm{~\psi~}~}}}{\overset{\mathrm{~M}}{}}\underset{\mathrm{~\mathrm{~\mathrm{~\psi~}~}}}{\overset{\mathrm{~M}}{}}\underset{\mathrm{~\mathrm{~\mathrm{~\psi~}~}}}{\mathrm{~\mathrm{~\mathrm{~\psi~}~}}}{\mathrm{~\mathrm{~\mathrm{~\psi~}~}}}{\mathrm{~\mathrm{~\mathrm{~\psi~}~}}}{\mathrm{~\mathrm{~\mathrm{~\psi~}~}}}{\mathrm{~\mathrm{~\mathrm{~\psi~}~}}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\mathrm{~\psi~}}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{\psi~}{
$$

式中：  $\#$  为遗忘因子；  $\#$  为输出节点的误差；  $\mathrm{y}_{\mathrm{i}}$  为输出节点的期望输出取E  $\mathbf{6}$  对权阵  $\mathbb{W}_{\mathrm{i}}\mathbb{G})$  的导数，并令其为零，且令

$$
\begin{array}{r}\mathrm{~R~}\mathfrak{G})=\mathrm{~\mathfrak{H}~}\mathfrak{H}\mathrm{~\mathfrak{G}~}-1)+\mathrm{~Z~}^{\mathrm{T}}\mathrm{~\mathfrak{G}}\mathrm{~Z~}\mathfrak{G}),\\\mathrm{~D~}_{\mathrm{i}}\mathfrak{G})=\mathrm{~\mathfrak{H}~}\mathfrak{H}\mathrm{~\mathfrak{G}~}-1)+\mathrm{~Z~}^{\mathrm{T}}\mathrm{~\mathfrak{G}}\mathrm{~y~}_{\mathrm{i}}\mathrm{~\mathfrak{G}~})\end{array}
$$

可得

$$
\mathrm{W}_{\mathrm{i}}^{\mathrm{T}}\mathrm{~\mathfrak{G}~}) = \mathrm{R}^{-1}\mathrm{~\mathfrak{G}~})\mathrm{D}_{\mathrm{i}}\mathrm{~\mathfrak{G}~}),
$$

$$
\mathrm{P}\mathrm{~\mathfrak{G}~}) = \mathrm{~\frac{1}{\hbar}~}\mathfrak{E}\mathrm{~\mathfrak{G}~} - 1) - \mathrm{~K~}\mathrm{~\mathfrak{G}~})\mathrm{Z~}\mathrm{~\mathfrak{G}~})\mathrm{P}\mathrm{~\mathfrak{G}~} - 1)],
$$

$$
\mathrm{K}\mathrm{~\mathfrak{G}~}) = \mathrm{~\frac{P}{\hbar}~}\mathrm{~\mathfrak{G}~} - 1)\mathrm{Z~}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\\ \mathrm{~\mathfrak{H}~} + \mathrm{~Z~}\mathrm{~\mathfrak{G}~})\mathrm{P}\mathrm{~\mathfrak{G}~} - 1)\mathrm{Z~}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{~\mathfrak{G}~} - 1)\mathrm{Z~}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{~\mathfrak{G}~} - 1)\mathrm{Z~}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{~\mathfrak{G}~} - 1)\mathrm{Z}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{~\mathfrak{G}~} - 1)\mathrm{Z}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{~\mathfrak{G}~} - 1)\mathrm{Z}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{\mathfrak{G}~} - 1)\mathrm{Z}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{\mathfrak{G}~} - 1)\mathrm{Z}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{\mathfrak{G}~} - 1)\mathrm{Z}^{\mathrm{T}}\mathrm{~\
$$

于是有

$$
\begin{array}{r}\mathrm{~W~}_{\mathrm{i}}^{\mathrm{T}}\mathrm{~\mathfrak{G}~}) = \mathrm{~W~}_{\mathrm{i}}^{\mathrm{T}}\mathrm{~\mathfrak{G}~} - 1) + \\ \mathrm{~K~}\mathrm{~\mathfrak{G}~}) = \mathrm{~W~}_{\mathrm{i}}\mathrm{~\mathfrak{G}~} - 1)\mathrm{~Z~}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{~\mathfrak{G}~} - 1)\mathrm{~Z~}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{~\mathfrak{G}~} - 1)\mathrm{~Z~}^{\mathrm{T}}\mathrm{~\mathfrak{G}~})\mathrm{~\mathfrak{G}~} - 1)\end{array}
$$

按照上述递推算法，最后可得  $\mathrm{E}\mathrm{~\mathfrak{G}~}) = \mathrm{E}_{\mathrm{min}}$

# 3故障检测的阈值选取

神经网络预测模型设计好以后，将已经训练好的径向基函数网络放到整个故障诊断系统中，便可以监控飞控系统：飞机正常飞行时，输出量的实际值与预测值间的残差趋于零；操纵面发生故障时，残差迅速偏离零位如果事先给定了阈值，一旦关于残差的某一表达式超过这一阈值，便认为有故障发生本文采用代价函数法来确定阈值

代价函数法就是构造某一特定的关于残差的函数，然后寻找合适的门限，使得当故障发生时残差超过此门限

在飞机故障检测阶段，考虑到发生操纵面故障时，飞机的3个角速度高度耦合，变化剧烈为了正确衡量残差，选取阈值的代价函数为

$$
\mathrm{COSTFUN}\mathrm{K}) = [\mathrm{K}\mathrm{K}) - \mathrm{K}\mathrm{K})^{2}+
$$

$\mathrm{K}) - \mathrm{K}\mathrm{K})^{2} + \mathrm{K}\mathrm{K}) - \mathrm{K}\mathrm{K})^{2}]^{\mathrm{T}}$  式中：  $\boxed{\boxed{\pi}}$  短 短为飞机的实际输出量；  $\boxed{\boxed{\pi}}$  短 短为对应预测量，定义

$\mathrm{e}\mathrm{K}) =$ $\boxed{\boxed{\pi}}$  短  $\mathrm{K}) - \mathrm{K}\mathrm{K})$  短  $\mathrm{K}) - \mathrm{K}\mathrm{K})$

$\boxed{\pi}$ $\mathrm{K}) - \mathrm{K}\mathrm{K})$

为残差向量实际监控中，关于残差的函数一旦超过阈值，便认为有故障发生

# 4仿真验证

针对某型歼击机，在  $\mathrm{Ma}$  为0.6，高度为  $5\mathrm{km}$  的平飞状态，几个操纵面发生卡死或缺损故障下，选取飞机的3个角速度为研究对象，用信号的前4个历史数据来预测第5个值，所以网络输入是将该信号分别延迟1至4个时间单位得到的4个分量为了达到预测精度，预测时取时间时延因子 $\mathrm{n} = 3$ $\mathrm{m} = 4$  ，即由飞机的输入uK），u  $\mathrm{K} - 1$  )，u

$- 2)$  ，u  $\mathrm{K} - 3$  )和输出  $\mathrm{y}\mathrm{K} - 1)$  ，y  $\mathrm{K} - 2)$  ，y  $\mathrm{K}-$  3），y  $\mathrm{K} - 4$  )来预测飞机的输出y  $\mathrm{K}$  ）u表示飞机的舵偏角和推力向量，即  $\mathrm{u} =$  撬 懒 懒 懒 $\mathrm{P}]^{\mathrm{T}}$  ：y表示飞机的3个角速度，即  $\mathrm{y} =$ $\mathrm{K}$ $\mathrm{K}$  取预测误差  $\mathrm{e}_{\mathrm{rr}} = 10^{- 4}$  ，对神经网络进行训练训练时输入向量P和目标向量T分别为： $\mathrm{P} = \mathrm{[}\mathrm{K}\mathrm{)}\mathrm{u}\mathrm{K} - 1)\mathrm{u}\mathrm{K} - 2)\mathrm{u}\mathrm{K} - 3)$ $\mathrm{y}\mathrm{K} - 1)\mathrm{y}\mathrm{K} - 2)\mathrm{y}\mathrm{K} - 3)\mathrm{y}\mathrm{K} - 4)],$ $\mathrm{T} = \mathrm{[}\mathrm{K})]$

为了测试网络的预测性能，用飞机正常平飞时的输入u输出y的4个时延信号序列作为样本在线输入，分别求出网络实际输出，然后与信号的实际值作比较

由于实际中信号都有极强的非线性，所以在仿真时加入了观测噪声来训练神经网络，这里加入均值为零，方差为0.2的白噪声经过多次仿真发现，只要增加足够多的网络输入样本值，增加隐含层的神经元个数及调整学习率，能够达到较好的预测性能

表1是各种故障下代价函数的变化幅度

表1各种故障下的代价函数的幅度  

<table><tr><td rowspan="2">故障
类型</td><td colspan="2">方向舵缺损</td><td colspan="2">卡死墩(°)</td><td colspan="4">副翼故障</td></tr><tr><td>100 %</td><td>-10</td><td>-5</td><td>5</td><td>10</td><td>20 %</td><td colspan="2">缺 损</td></tr><tr><td>代价函数</td><td>2.6915</td><td>4.9242</td><td>4.3003</td><td>4.3017</td><td>4.9251</td><td>1.5104</td><td>1.6973</td><td>1.9510</td></tr><tr><td>故障
类型</td><td>-10</td><td>-5</td><td></td><td colspan="5">缺 损</td></tr><tr><td>代价函数</td><td>6.5011</td><td>5.9167</td><td></td><td>2.0044</td><td>2.6511</td><td>3.4642</td><td></td><td></td></tr></table>

权衡每种故障下残差代价函数的变化，选取阈值THRES.F.D.为1.5，既可保证准确检测出故障，又可降低误检率

# 参考文献

Patton R J. Fault detection and diag nosis in aerospace systems using analytical redundancy [J]. IEE Com porting & Control Eng,1991,2 8):127~136. Sorsa T, Koivo H N. A pplication of artificial neural network in process fault- diag nosis [J]. Au tom atica,1993,29

4):843~849.

作者简介：

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/5e1ff204-713d-4689-a2f7-dde4798d729f/78ca84c06418c0303807e9b1fab3bffd9564685a565b8a7a3f74e17aab14c347.jpg)

汪晨曦 1974年生，硕士，研究方向为通讯系统的故障识别