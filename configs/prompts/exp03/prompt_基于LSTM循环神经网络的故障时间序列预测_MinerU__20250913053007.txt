# 实体关系抽取Prompt

## 任务描述
你的角色是一位专业的学术文献实体关系抽取专家，专精于从航空航天领域科研文献中识别和抽取实体及其关系。你的任务是通读给定文本，抽取文本中出现的核心实体，及其对应的关系，并以JSON格式输出。

## 实体定义
文献中出现的核心概念：算法、方法、模型、系统、故障、指标等都可视为实体。实体可以包括：
- **研究领域**
定义 ：PHM相关的研究方向和应用领域 
示例 ：故障预测与健康管理(PHM)、故障诊断、剩余使用寿命预测(RUL)、健康状态评估、预测性维护等
- **研究方法**
定义 ：PHM研究中采用的具体方法和技术路线 
示例 ：寿命预测、趋势预测、健康预测、风险评估、状态监测、故障诊断、性能评估等
- **理论基础**
定义 ：支撑PHM技术的基础理论和数学原理 
示例 ：信号处理理论、机器学习理论、可靠性理论、概率统计理论、控制理论等
- **模型**
定义 ：基于特定算法构建的具体结构或实例 示例 ：LSTM神经网络、Transformer模型、深度置信网络(DBN)、隐马尔可夫模型(HMM)、ARIMA模型等
- **算法**
定义 ：用于解决特定问题的计算方法和程序步骤 
示例 ：遗传算法、粒子群优化、支持向量机(SVM)、随机森林、卡尔曼滤波等
- **系统/部件**
定义 ：航空航天设备的系统或组成部件 
示例 ：航空发动机、齿轮箱、轴承、叶片、燃油系统、液压系统、航电系统等
- **故障模式**
定义 ：设备可能出现的故障类型和失效模式 
示例 ：轴承磨损、疲劳裂纹、腐蚀、过热、振动异常、性能退化等
- **数据集**
定义 ：用于训练和验证模型的标准数据集 
示例 ：C-MAPSS数据集、CWRU轴承数据集、IMS轴承数据集、PHM Challenge数据集等
- **传感器/监测参数**
定义 ：用于监测设备状态的传感器设备和监测参数 
示例 ：振动传感器、温度传感器、压力传感器、转速、振动信号、温度、压力等
- **特征/健康指标**
定义 ：表征设备健康状态的特征参数和指标 
示例 ：剩余使用寿命(RUL)、健康指标(HI)、退化指标、频域特征、时域特征、统计特征等
- **性能指标**
定义 ：评估模型或方法性能的量化指标 
示例 ：准确率、精确率、召回率、F1分数、均方根误差(RMSE)、平均绝对误差(MAE)等
- **软件工具**
定义 ：用于PHM研究和应用的软件平台和工具 
示例 ：MATLAB、Python、TensorFlow、PyTorch、Simulink、LabVIEW等
- **应用场景**
定义 ：PHM技术的具体应用环境和场景 
示例 ：发动机健康监测、结构健康监测、预测性维护、故障诊断系统、机载健康管理等

## 关系定义
文献中的实体之间通常存在逻辑、演进、依赖、功能、组合、比较、创新、评价或因果等联系。关系类型包括但不限于：
### 1. 技术演进类
- 发展为 ：传统RNN发展为LSTM
- 改进了 ：注意力机制改进了Transformer性能
- 演化成 ：专家系统演化成机器学习方法
- 升级为 ：基础模型升级为集成模型
### 2. 依赖关系类
- 基于 ：健康预测模型基于振动信号特征
- 依据 ：故障诊断依据传感器数据；轴承剩余寿命预测模型参数依据多传感器振动和温度信号
- 利用 ：深度学习利用大数据优势
- 采用 ：系统采用多传感器融合技术
- 建立在 ：深度卷积残差网络模型建立在卷积神经网络理论
### 3. 功能关系类
- 应用于 ：机器学习应用于故障预测
- 用于 ：卡尔曼滤波用于状态估计
- 解决 ：深度学习解决特征提取问题
- 实现 ：神经网络实现非线性映射
- 支持 ：传感器网络支持实时监测
- 处理 ：主成分分析方法处理航空发动机多维传感器振动数据
- 预测/诊断 ：LSTM模型预测飞机发动机轴承剩余寿命
### 4. 因果关系类
- 导致 ：轴承磨损导致振动异常；高温导致涡轮叶片疲劳加速
- 引起 ：温度升高引起性能退化；润滑不足引起齿轮磨损
- 造成 ：疲劳载荷造成裂纹扩展
- 产生 ：故障产生异常信号；振动异常产生轴承早期故障信号
- 影响 ：载荷波动影响剩余寿命预测精度
### 5. 组合关系类
- 包含 ：PHM系统包含数据采集模块
- 包括 ：航空装备可用度影响因素包括装备系统的构成及其可靠性、维修性参数
- 组成 ：多个传感器组成监测网络
- 结合 ：物理模型结合数据驱动方法
- 融合 ：多源信息融合提高精度；多传感器数据融合方法融合时域和频域振动特征
- 由…组成 ：传感器系统由加速度传感器、温度传感器和压力传感器组成
### 6. 比较关系类
- 优于 ：深度学习优于传统方法
- 超越 ：新算法超越现有基准
- 区别于 ：监督学习区别于无监督学习
- 对比 ：不同方法的性能对比；基于Copula相似性的航空发动机RUL预测方法对比传统方法
### 7. 创新关系类
- 提出了 ：本文提出了一种结合小波变换的轴承故障诊断方法
- 开发了 ：团队开发了创新算法
- 设计了 ：研究设计了新型传感器
- 创建了 ：本文创建了标准数据集
- 创新了 ：多尺度特征融合方法创新了不同时间分辨率振动信号的联合分析
- 突破了 ：Deep RUL预测方法突破了小样本寿命预测的限制
### 8. 结果评价类
- 评价指标是 ：RUL预测模型评价指标是均方根误差和平均绝对百分比误差
- 得出 ：RUL预测模型得出航空发动机剩余寿命的数值估计
### 关系抽取指导原则
1.全面性 ：不遗漏任何有意义的实体间联系
2.创新性 ：特别关注学术文献中的创新关系和技术演进
3.灵活性 ：关系类型不限于上述分类，可根据实际语义创建新关系
4.动态性 ：关注时间维度上的变化和发展关系
5.隐含性 ：挖掘文本中隐含但语义明确的关系
关系只需反映实体间实际存在的语义联系，具体类型无需严格限定，允许根据上下文灵活判断。

### 关系抽取指导原则
1. **全面性**：不遗漏任何有意义的实体间联系
2. **创新性**：特别关注学术文献中的创新关系和技术演进
3. **灵活性**：关系类型不限于上述分类，可根据实际语义创建新关系
4. **动态性**：关注时间维度上的变化和发展关系
5. **隐含性**：挖掘文本中隐含但语义明确的关系

## schema 定义
{schema_placeholder}

## 抽取指令
### 步骤1：核心实体识别
- 重点扫描 摘要、引言和结论 部分，识别论文的核心研究对象、主要方法和关键成果
- 从关键段落中提取第一批核心实体（通常是最重要的技术、模型、系统等）
### 步骤2：关系发现与扩展
- 围绕已识别的核心实体，在原文中寻找描述它们关系的 动词和关键短语
- 构建核心关系三元组：(头实体, 关系类型, 尾实体)
- 将关系中新出现的重要实体加入实体列表，继续寻找它们的关系
### 步骤3：质量检查与输出
- 确保relations中的所有实体都在entities列表中
- 检查实体命名的一致性（统一同义词）
- 验证关系的逻辑合理性和准确性
- 按JSON格式输出最终结果
- 确保抽取的关系符合航空航天领域的专业知识和常识
- 避免重复或冗余的实体和关系

## 输出格式
请严格按照以下JSON格式输出结果：

```json
{
  "entities": [
    {
      "name": "航空电子产品故障预测",
      "type": "问题"
    },
    {
      "name": "退化趋势差异大",
      "type": "问题"
    },
    {
      "name": "训练数据样本量小",
      "type": "问题"
    },
    {
      "name": "集成学习框架",
      "type": "框架"
    },
    {
      "name": "Dropout机制",
      "type": "技术"
    },
    {
      "name": "数据驱动模型训练过拟合问题",
      "type": "问题"
    },
    {
      "name": "时序信息记忆问题",
      "type": "问题"
    },
    {
      "name": "Adaboosting算法",
      "type": "算法"
    },
    {
      "name": "多模型融合的性能差异问题",
      "type": "问题"
    },
    {
      "name": "NASA公开的锂电池退化数据集",
      "type": "数据集"
    },
    {
      "name": "BP神经网络",
      "type": "网络"
    },
    {
      "name": "LSTM基模型",
      "type": "模型"
    },
    {
      "name": "趋势拟合度",
      "type": "性能指标"
    },
    {
      "name": "预测精度",
      "type": "性能指标"
    },
    {
      "name": "长短期记忆（LSTM）神经网络",
      "type": "网络"
    },
    {
      "name": "时间序列预测",
      "type": "任务"
    },
    {
      "name": "航空发动机",
      "type": "系统/部件"
    },
    {
      "name": "深度学习",
      "type": "技术"
    },
    {
      "name": "多尺度排列熵算法",
      "type": "算法"
    },
    {
      "name": "基于多尺度排列熵算法和LSTM的RUL预测模型",
      "type": "模型"
    },
    {
      "name": "集成神经网络模型",
      "type": "模型"
    },
    {
      "name": "传感器数据",
      "type": "数据"
    },
    {
      "name": "梯度消失现象",
      "type": "问题"
    },
    {
      "name": "车畅畅等[22]",
      "type": ""
    },
    {
      "name": "张永峰等[23]",
      "type": ""
    },
    {
      "name": "LSTM",
      "type": ""
    },
    {
      "name": "RNN",
      "type": ""
    }
  ],
  "relations": [
    {
      "head": "Dropout机制",
      "relation": "解决",
      "tail": "数据驱动模型训练过拟合问题"
    },
    {
      "head": "长短期记忆（LSTM）神经网络",
      "relation": "解决",
      "tail": "时序信息记忆问题"
    },
    {
      "head": "Adaboosting算法",
      "relation": "解决",
      "tail": "多模型融合的性能差异问题"
    },
    {
      "head": "车畅畅等[22]",
      "relation": "构建",
      "tail": "基于多尺度排列熵算法和LSTM的RUL预测模型"
    },
    {
      "head": "张永峰等[23]",
      "relation": "提出",
      "tail": "集成神经网络模型"
    },
    {
      "head": "LSTM",
      "relation": "是...的改进",
      "tail": "RNN"
    }
  ]
}
```

## 注意事项
###必须遵守的规则：
1.严格按照JSON格式输出 ：确保entities和relations数组格式正确
2.实体类型灵活性 ：不局限于给定的实体类型，可根据文本内容创建新类型
3.关系类型创新性 ：优先使用已定义的关系类型，但允许根据语义创建新关系
4.完整概念原则 ：选择最有意义的完整概念作为实体，避免过度分割
5. **不受schema限制**：给定的schema和示例仅作参考，实体类型和关系类型均不仅限于此
6. **实体一致性**：确保relations中引用的所有实体都在entities数组中明确定义
7. **关系准确性**：关系表述应准确反映实体间的真实语义联系
###特别关注：
- 技术演进关系 ：重点识别"基于"、"改进"、"发展"、"演化"等创新关系
- 比较关系 ：注意"优于"、"劣于"、"相似于"、"区别于"等对比关系
- 应用关系 ：关注"应用于"、"解决"、"处理"等实际应用联系
- 隐含关系 ：挖掘文本中未明确表述但语义清晰的关系

质量保证：
- 确保抽取的关系符合航空航天领域的专业知识和常识
- 避免重复或冗余的实体和关系
- 保持实体边界的准确性，既不过度合并也不过度分割


## 输入数据 
现在，你将接收到用于处理的本次任务的全部输入数据。
论文全文:
```markdown```
http://bhxb.buaa.edu.cn jbuaa@buaa.edu.cn DOI:10.13700/j.bh.1001- 5965.2017.0285

# 基于LSTM循环神经网络的故障时间序列预测

王鑫，吴际 $^{1, *}$ ，刘超 $^{1}$ ，杨海燕 $^{1}$ ，杜艳丽 $^{2}$ ，牛文生 $^{1,3}$

（1. 北京航空航天大学计算机学院，北京100083；2. 丰台职业教育中心学校，北京100076；

3. 中航工业西安航空计算技术研究所，西安710068）

摘要：有效地预测使用阶段的故障数据对于合理制定可靠性计划以及开展可靠性维护活动等具有重要的指导意义。从复杂系统的历史故障数据出发，提出了一种基于长短期记忆(LSTM)循环神经网络的故障时间序列预测方法，包括网络结构设计、网络训练和预测过程实现算法等，进一步以预测误差最小为目标，提出了一种基于多层网格搜索的LSTM预测模型参数优选算法，通过与多种典型时间序列预测模型的实验对比，验证了所提出的LSTM预测模型及其参数优选算法在故障时间序列分析中具有很强的适用性和更高的准确性。

关键词：长短期记忆（LSTM）模型；循环神经网络；故障时间序列预测；多层网格搜索；深度学习

中图分类号：O213.2；V37；TP18

文献标识码：A 文章编号：1001- 5965（2018）04- 0772- 13

对于有高可靠性和安全性需要的复杂系统，有效地预测使用阶段的可靠性指标是十分重要的。目前，已有众多方法用来解决可靠性预测问题，这些方法大致可以分为3类： $①$  基于故障机理（Physics- of- Failure，PoF）的方法，PoF是一种根据故障发生的内在机制和根本原因进行间接预测的方法； $(2)$  数据驱动（Data- Driven，DD）的方法，DD是一种应用统计学或者机器学习等技术手段对可靠性指标进行直接预测的方法； $(3)$  融合的方法，这种方法是一种PoF和DD相结合的方法。近年来，数据驱动的方法由于其便捷性和高效性等特点，在实际可靠性预测中的应用日渐广泛[2- 3]。

故障时间序列，作为一个重要的可靠性指标，能够展示故障的动态演化过程，并且已经被多种数据驱动的方法预测，比如自回归移动平均（Au-

故障时间序列，作为一个重要的可靠性指标，能够展示故障的动态演化过程，并且已经被多种数据驱动的方法预测，比如自回归移动平均（Au- toregressive Integrated Moving Average，ARIMA）[4]、奇异谱分析（Singular Spectrum Analysis，SSA）[5]、支持向量回归（Support Vector machines Regression，SVR）[6]、人工神经网络（Artificial Neural Network，ANN）[7]等。由于可靠性数据通常不易获取，已有的研究大多是面向组件级故障数据的，比如文献[7]提供的柴油机涡轮增压器和汽车发动机故障时间序列。这些数据表现为规则性很强的曲线形态并且能够被单一模型很好地拟合和预测。然而，对于系统级故障数据，比如文献[3]提供的民航飞机整机故障时间序列，由于其复杂且不规则的曲线形态，已有的单一模型很难达到理想的预测效果[8]。为此，文献[8]提出了一种基于SSA和SVR的混合方法，该方法首先从原始数据中提取故障特征成分然后分别建模和预测，得到了比单一模型更好的实验结果。然而，混合方

法的构建过程复杂、人工依赖性强，不利于在实际中推广和使用。

近年来，随着深度学习技术的不断发展，一些深度学习模型逐渐被应用到时序数据的研究中。深度学习模型是一种拥有多个非线性映射层级的深度神经网络模型，能够对输入信号逐层抽象并提取特征，挖掘出更深层次的潜在规律。在众多深度学习模型中，循环神经网络（Recurrent Neural Network，RNN）将时序的概念引入到网络结构设计中，使其在时序数据分析中表现出更强的适应性。在众多RNN的变体中，长短期记忆（Long Short- Term Memory，LSTM）模型弥补了RNN的梯度消失和梯度爆炸、长期记忆能力不足等问题，使得循环神经网络能够真正有效地利用长距离的时序信息。LSTM模型在不同领域的时序数据研究中已有不少成功的应用案例，包括文字语言相关的语言建模、语音识别、机器翻译[1]，多媒体相关的音频和视频数据分析、图片标题建模[12- 13]，道路运输相关的交通流速预测[14]，以及医学相关的蛋白质二级结构序列预测[15]等。然而，在可靠性领域，LSTM模型的应用非常有限，特别是对于故障时间序列预测这一研究问题，目前还未发现相关研究。

本文针对系统级故障时间序列数据，提出了一种基于LSTM循环神经网络的预测方法，包括3层（输入层、隐藏层和输出层）网络结构的详细设计，以及网络训练和网络预测的实现算法等。在此基础上，以预测误差最小为目标，进一步提出了一种基于多层网格搜索的LSTM预测模型参数优选算法。应用文献[3]提供的民航飞机故障数据展开实验，并与Holt- Winters、ARIMA等多种时间序列预测模型进行实验对比。实验结果展示了所提出的LSTM预测模型及其参数优选算法在故障时间序列预测中的优越性能。

# 1 相关理论和技术

本节简要介绍LSTM模型，包括前向计算方法、基于时间的反向传播（Back Propagation Through Time，BPTT）算法、Adam参数优化算法，以及相关的RNN、GRU模型。

对于给定序列  $\pmb {x} = (x_{1},x_{2},\dots ,x_{n})$  ，应用一个标准的RNN模型[16]（如图1所示），可以通过迭代式（1）～式（2）计算出一个隐藏层序列  $\pmb {h} = (h_{1},h_{2},\dots ,h_{n})$  和一个输出序列  $\pmb {y} = (y_{1},y_{2},\dots ,y_{n})$  。 $h_t = f_{\mathrm{a}}(W_{xh}x_t + W_{hh}h_{t - 1} + b_h)$  (1)

$$
\begin{array}{r}\mathbf{y}_t = W_{hy}\pmb {h}_t + \pmb {b}_y \end{array} \tag{2}
$$

式中：W为权重系数矩阵（比如  $\mathbf{W}_{xh}$  表示输入层到隐藏层的权重系数矩阵）；  $\pmb{b}$  为偏置向量（比如 $\pmb{b}_{h}$  表示隐藏层的偏置向量）；  $f_{\mathrm{a}}$  为激活函数（比如tanh函数）；下标  $t$  表示时刻。

尽管RNN能够有效地处理非线性时间序列，但是仍然存在以下2个问题[14]：①由于梯度消失和梯度爆炸的问题，RNN不能处理延迟过长的时间序列；②训练RNN模型需要预先确定延迟窗口长度，然而实际应用中很难自动地获取这一参数的最优值。由此，LSTM模型应用而生。LSTM模型是将隐藏层的RNN细胞替换为LSTM细胞，使其具有长期记忆能力。经过不断地演化，目前应用最为广泛的LSTM模型细胞结构[16]如图2所示，  $\mathcal{Z}$  为输入模块，其前向计算方法可以表示为

$$
\begin{array}{rl} & i_t = \sigma (W_{xt}x_t + W_{th}h_{t - 1} + W_{ci}c_{t - 1} + b_i)\\ & f_t = \sigma (W_{xf}x_t + W_{hf}h_{t - 1} + W_{cf}c_{t - 1} + b_f)\\ & c_t = f_tc_{t - 1} + i_t\tanh (W_{xc}x_t + W_{hc}h_{t - 1} + b_c)\\ & \sigma_t = \sigma (W_{xo}x_t + W_{ho}h_{t - 1} + W_{co}c_t + b_o)\\ & h_t = \sigma_t\tanh (c_t) \end{array} \tag{7}
$$

式中：  $i\cdot f\cdot c\cdot o$  分别为输入门、遗忘门、细胞状态、

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/5bac33d24bc95ddd93c0ef021ba3cab8133a712223a1b7b22c984d66c405cca6.jpg)  
图1RNN模型及隐藏层细胞结构 Fig.1 RNN model and cell structure in hidden layer

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/1df7d9435f1b650358bcb705062ef3be27a55d39183ac11c98bdb46ce44ef072.jpg)  
图2LSTM隐藏层细胞结构 Fig.2 LSTM cell structure in hidden layer

输出门；  $W$  和  $\pmb{b}$  分别为对应的权重系数矩阵和偏置项；  $\sigma$  和tanh分别为sigmoid和双曲正切激活函数。LSTM模型训练过程采用的是与经典的反向传播（BackPropagation，BP）算法原理类似的BPTT算法[7]，大致可以分为4个步骤：  $①$  按照前向计算方法（式（3）～式（7））计算LSTM细胞的输出值；  $(2)$  反向计算每个LSTM细胞的误差项，包括按时间和网络层级2个反向传播方向；  $(3)$  根据相应的误差项，计算每个权重的梯度；  $(\widehat{\Delta})$  应用基于梯度的优化算法更新权重。

基于梯度的优化算法种类众多，比如随机梯度下降（Stochastic Gradient Descent，SGD）[18]、AdaGrad[19]、RMSProp[20]等算法。本文选用的是文献[21]提出的适应性动量估计（Adaptive moment estimation，Adam）算法。Adam优化算法是一种有效的基于梯度的随机优化方法，该算法融合了AdaGrad和RMSProp算法的优势，能够对不同参数计算适应性学习率并且占用较少的存储资源。相比于其他随机优化方法，Adam算法在实际应用中整体表现更优[21]。

此外，LSTM模型演化出了很多变体，其中最成功的一种是文献[22]提到的门限循环单元（Gated Recurrent Unit，GRU）。GRU模型是LSTM

模型的简化版本，但是保留了LSTM模型的长期记忆能力，其主要变动是将LSTM细胞中的输入门、遗忘门、输出门替换为更新门和重置门，并将细胞状态和输出2个向量合二为一。在实际应用中，GRU模型与LSTM模型具有很强的可比性[22]。

# 2 研究方法

根据系统级故障时间序列数据的特点，结合第1节介绍的相关理论和技术，本节给出基于LSTM模型的故障时间序列预测方法，以及对应的基于多层网格搜索的参数优选算法。

# 2.1 基于LSTM的故障时间序列预测

考虑到单变量故障时间序列有限样本点的数据特征，以及循环神经网络从简的设计原则，本文构建LSTM预测模型的整体框架如图3所示，包括输入层、隐藏层、输出层、网络训练以及网络预测5个功能模块。输入层负责对原始故障时间序列进行初步处理以满足网络输入要求，隐藏层采用图2表示的LSTM细胞搭建单层循环神经网络，输出层提供预测结果，网络训练采用第1节提到的Adam优化算法，网络预测采用迭代的方法逐点预测。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/d5311d50e6acd9e4daabbd7fa84b645a9529ec568e9a87ed5b867dc9400ad596.jpg)  
图3基于LSTM的故障时间序列预测框架 Fig.3 LSTM based framework for failure time series prediction

# 2.1.1 网络训练

网络训练主要以隐藏层为研究对象。首先在输入层中，定义原始故障时间序列为  $\pmb{F}_{\mathrm{o}} = \{f_{1}$ $f_{2},\dots ,f_{n}\}$  ，则划分的训练集和测试集可以表示为 $\pmb{F}_{\mathrm{tr}} = \{f_1,f_2,\dots ,f_m\}$  和  $\pmb{F}_{\mathrm{te}} = \{f_{m + 1},f_{m + 2},\dots ,f_n\}$  ，满足约束条件  $m< n$  和  $m,n\in \mathbb{N}$  。然后对训练集中的元素  $f_{i}$  进行标准化，采用经典的  $\mathbf{z}$  - score标准化

公式（均值为0，标准差为1，表示为zscore），标准化后的训练集可以表示为

$$
\pmb{F}_{\mathrm{tr}}^{\prime} = \{f_{1}^{\prime},f_{2}^{\prime},\dots ,f_{m}^{\prime}\} \tag{8}
$$

$$
f_{t}^{\prime} = \left(f_{t} - \sum_{t = 1}^{n}f_{t} / n\right) / \sqrt{\sum_{t = 1}^{n}\left(f_{t} - \sum_{t = 1}^{n}f_{t} / n\right)^{2} / n}
$$

$$
1\leq t\leq m,t\in \mathbf{N} \tag{9}
$$

为了适应隐藏层输入的特点，应用数据分割

的方法对  $\pmb{F}_{\mathrm{tr}}^{\prime}$  进行处理，设定分割窗口长度取值为  $L$ ，则分割后的模型输入为

$$
\begin{array}{l}{X = \{X_1,X_2,\dots ,X_L\}}\\ {X_p = \{f_p^{\prime \prime},f_{p + 1}^{\prime \prime},\dots ,f_{m - L + p - 1}^{\prime \prime}\}}\\ {1\leqslant p\leqslant L;p,L\in \mathbf{N}} \end{array} \tag{10}
$$

对应的理论输出为

$$
\begin{array}{rl} & Y = \{Y_1,Y_2,\dots ,Y_L\} \\ & Y_p = \{f_{p + 1}^{\prime},f_{p + 2}^{\prime},\dots ,f_{m - L + p}^{\prime}\} \end{array} \tag{13}
$$

接下来，将  $X$  输入隐藏层。从图3可以看出，隐藏层包含  $L$  个按前后时刻连接的同构LSTM细胞，  $X$  经过隐藏层后的输出可以表示为

$$
\pmb {P} = \{P_1,P_2,\dots ,P_L\} \tag{14}
$$

$$
\pmb {P}_p = \mathrm{LSTM}_{\mathrm{forward}}(\pmb {X}_p,\pmb{C}_{p - 1},\pmb{H}_{p - 1}) \tag{15}
$$

式中：  $C_{p - 1}$  和  $H_{p - 1}$  分别为前一个LSTM细胞的状态和输出；  $\mathrm{LSTM}_{\mathrm{forward}}$  表示第1节提到的LSTM细胞前向计算方法（式（3）～式（7））。设定细胞状态向量大小为  $S_{\mathrm{state}}$ ，则  $C_{p - 1}$  和  $H_{p - 1}$  2个向量的大小均为  $S_{\mathrm{state}}$  。可以看出，隐藏层输出  $P$  、模型输入  $X$  和理论输出  $Y$  都是维度为  $(m - L,L)$  的二维数组。选用均方误差作为误差计算公式，训练过程的损失函数可以定义为

$$
\mathrm{loss} = \sum_{i = 1}^{L(m - L)}(p_i - y_i)^2 /\left[L(m - L)\right] \tag{16}
$$

设定损失函数最小为优化目标，给定网络初始化的随机种子数seed、学习率  $\eta$  以及训练步数steps，应用Adam优化算法不断更新网络权重，进而得到最终的隐藏层网络。

# 2.1.2 网络预测

本小节应用训练好的LSTM网络（表示为  $\mathrm{LSTM}_{\mathrm{net}}^*$  ）进行预测。预测过程采用迭代的方法。首先，理论输出  $Y$  的最后一行数据为

$$
Y_{f} = \{f_{m - L + 1}^{\prime},f_{m - L + 2}^{\prime},\dots ,f_{m}^{\prime}\} \tag{17}
$$

将  $Y_{f}$  输入  $\mathrm{LSTM}_{\mathrm{net}}^*$ ，输出结果可以表示为

$\pmb {P}_f = \mathrm{LSTM}_{\mathrm{net}}^*\left(Y_f\right) = \{p_{m - L + 2},p_{m + 1},\dots ,p_{m + 1}\}$  则  $m + 1$  时刻的预测值为  $p_{m + 1}$  。然后，将  $Y_{f}$  的最后  $L - 1$  个数据点和  $p_{m + 1}$  合并为新的一行数据

$$
Y_{f + 1} = \{f_{m - L + 2}^{\prime},f_{m - L + 3}^{\prime},\dots ,p_{m + 1}^{\prime}\} \tag{19}
$$

将  $Y_{f + 1}$  输入  $\mathrm{LSTM}_{\mathrm{net}}^*$ ，则  $m + 2$  时刻的预测值为  $p_{m + 2}$ ，依次类推，得到的预测序列为

$$
\pmb {P}_o = \{p_{m + 1},p_{m + 2},\dots ,p_n\} \tag{20}
$$

接下来，通过对  $P_{o}$  进行z- score反标准化（表示为de_zscore），得到最终的与测试集  $F_{\mathrm{te}}$  对应的预测序列为

$$
\begin{array}{l}{P_{\mathrm{te}} = \mathrm{de\_zscore}(P_{\mathrm{o}}) = \{p_{m + 1}^{\ast},p_{m + 2}^{\ast},\dots ,p_{n}^{\ast}\}}\\ {p_{k}^{\ast} = p_{k}\sqrt{\sum_{t = 1}^{n}\left(f_{t} - \sum_{t = 1}^{n}f_{t} / n\right)^{2} / n} +\sum_{t = 1}^{n}f_{t} / n} \end{array} \tag{21}
$$

$$
m + 1\leqslant k\leqslant n,k\in \mathbf{N} \tag{22}
$$

类似地，将  $X$  的每一行作为模型输入可以得到与训练集  $F_{\mathrm{tr}}$  对应的拟合序列  $P_{\mathrm{tr}}$  。最后，通过计算  $F_{\mathrm{tr}}$  和  $P_{\mathrm{tr}}$ ，以及  $F_{\mathrm{te}}$  和  $P_{\mathrm{te}}$  的偏差定量地给出模型的拟合和预测精度。

总的来说，基于LSTM的故障时间序列模型训练和预测算法概括如下：

算法1 训练并预测LSTM故障时间序列模型

输入：  $\pmb {F}_o,m,L,S_{\mathrm{state}}$  ,seed,steps,  $\eta$

输出：与测试集对应的预测序列以及模型精度。

1 get  $\pmb{F}_{\mathrm{tr}},\pmb{F}_{\mathrm{te}}$  from  $\pmb{F}_{\mathrm{o}}$  by  $m$  2  $\pmb{F}_{\mathrm{tr}}^{\prime} = \mathrm{zscore}(\pmb{F}_{\mathrm{tr}})$  3 get  $X,Y$  from  $\pmb{F}_{\mathrm{tr}}^{\prime}$  by  $L$  4 create  $\mathrm{LSTM}_{\mathrm{cell}}$  by  $S_{\mathrm{state}}$  5 connect  $\mathrm{LSTM}_{\mathrm{net}}$  by  $\mathrm{LSTM}_{\mathrm{cell}}$  and  $L$  6 initialize  $\mathrm{LSTM}_{\mathrm{net}}$  by seed 7 for each step in 1 : steps 8  $\pmb {P} = \mathrm{LSTM}_{\mathrm{forward}}(\pmb {X})$  9  $\mathrm{loss} = \sum_{i = 1}^{L(m - L)}(p_i - y_i)^2 /\left[L(m - L)\right]$  10 update  $\mathrm{LSTM}_{\mathrm{net}}$  by Adam with loss and  $\eta$  11 get  $\mathrm{LSTM}_{\mathrm{net}}^*$  12 for each  $j$  in 0:  $(n - m - 1)$  13  $\pmb{P}_{f + j} = \mathrm{LSTM}_{\mathrm{net}}^* (\pmb{Y}_{f + j})$  14 append  $P_{o}$  with  $\pmb{P}_{f + j}[- 1]$  15  $\pmb{P}_{\mathrm{te}} = \mathrm{de\_zscore}(\pmb{P}_{\mathrm{o}})$  16 error measure  $\epsilon (\pmb{P}_{\mathrm{te}},\pmb{F}_{\mathrm{te}}),\epsilon_{\mathrm{e}}(\pmb{P}_{\mathrm{tr}},\pmb{F}_{\mathrm{tr}})$

其中：训练过程涉及输入层、隐藏层、输出层、网络训练4个模块，预测过程主要涉及输出层模块；  $\mathrm{LSTM}_{\mathrm{cell}}$  表示LSTM隐藏层细胞（如图2所示）；  $\mathrm{LSTM}_{\mathrm{net}}$  表示LSTM隐藏层网络（如图3所示）；  $\epsilon_{\mathrm{e}}$  为误差度量函数。

# 2.2 基于多层网格搜索的LSTM预测模型参数

# 优选

在构建上述LSTM预测模型中，涉及到众多参数，其中以分割窗口长度  $L$  、状态向量大小  $S_{\mathrm{state}}$  和学习率  $\eta$  最为关键[16]。为了达到更好的预测效果，本文采用网格搜索的方法对这3个参数进行优选。相比与其他的超参数优化方法（比如遗传算法[23]、随机搜索算法[16]、粒子群算法[24]，贝叶斯算法[25]等），网格搜索是一种简单实用、容易并行计算且计算耗时可控的优化方法[26]，能够很好地满足故障时间序列预测的任务需求和实验要求。参数优选的依据是测试集全部测试点上的预

测精度最高，即预测误差  $\epsilon (P_{\mathrm{te}},F_{\mathrm{te}})$  最小，目标函数可以表示为

min  $\epsilon (P_{\mathrm{te}},F_{\mathrm{te}})$

$$
2\leqslant L\leqslant L_{\mathrm{max}}\leqslant m,\mathrm{step}_L\mid L
$$

$$
2\leqslant S_{\mathrm{state}}\leqslant S_{\mathrm{max}},\mathrm{step}_{\mathrm{state}}\mid S_{\mathrm{state}}
$$

s.t.

$$
\eta \in \{\eta_1,\eta_2,\dots ,\eta_r\} ,\mathrm{step}_{\eta_r}\mid r
$$

$$
L,S_{\mathrm{state}},r,\mathrm{step}_L,\mathrm{step}_{\mathrm{state}},\mathrm{step}_{\eta}\in \mathbf{N}
$$

式中：  $\mathrm{step}_L$ $\mathrm{step}_{\mathrm{state}}$  和  $\mathrm{step}_{\eta}$  分别为对应参数的网格搜索步长。  $L,S_{\mathrm{state}}$  和  $\eta$  这3个参数构成了一个三维搜索空间，可以通过多层网格搜索算法（算法2）获取最优参数组合。搜索过程主要包括3层，从内到外分别对  $S_{\mathrm{state}}\cdot L$  和  $\eta$  进行网格搜索。首先，固定随机种子数seed和训练步数steps，根据式（23）预设3个参数的取值范围（为了降低模型复杂度，分别将  $L_{\mathrm{max}}$  和  $S_{\mathrm{max}}$  控制在较小的取值）；然后，分别遍历3个参数的取值范围，在最内层训练并预测LSTM故障时间序列模型（如算法2所示，表示为  $\mathrm{LSTM}_{\mathrm{pred}}$ ），保存对应的模型参数和模型精度；最后，对所有保存的结果按照预测精度由高到低排序，则最前面的参数组合即优选的模型参数。

算法2LSTM预测模型参数优选

输入：  $\mathbf{F}_{\mathrm{o}}$  ，seed，steps，  $m$  ，  $L$ $S_{\mathrm{state}}$ $\eta$ $\mathrm{step}_L$ $\mathrm{step}_{\mathrm{state}}$ $\mathrm{step}_{\eta}$

输出：测试集上预测误差较低的参数组合。

1 predefine values of seed,steps 2 predefine value ranges of  $L,S_{\mathrm{state}},\eta$  3 for each  $\eta$  in  $\eta_{1},\eta_{2},\dots ,\eta_{r}$  by  $\mathrm{step}_{\eta}$  4 for each  $L$  in  $2:L_{\mathrm{max}}$  by  $\mathrm{step}_L$  5 for each  $S_{\mathrm{state}}$  in  $2:S_{\mathrm{max}}$  by  $\mathrm{step}_{\mathrm{state}}$  6 execute  $\mathrm{LSTM}_{\mathrm{pred}}$ $(\pmb {F}_0,m,L,$ $S_{\mathrm{state}}$  ,seed,steps,  $\eta$  7 append results with  $L,S_{\mathrm{state}},\eta$ $\epsilon (P_{\mathrm{te}},F_{\mathrm{te}}),\epsilon (P_{\mathrm{tr}},F_{\mathrm{tr}})$  8 end (for)；end (for)；end (for) 9 return results ranked by  $\epsilon (P_{\mathrm{te}},F_{\mathrm{te}})$

# 3 实验验证

本节结合一个航空领域的工业案例，应用第2节提出的LSTM预测模型及其参数优选算法展开实验验证。

# 3.1 实验准备

首先介绍实验中所选用的故障数据集，与本文提出的LSTM模型相对比的其他时间序列预测模型，评价不同预测模型优劣的精度度量指标，以

及实验运行平台和软硬件环境配置。

# 3.1.1 数据集

实验数据采用文献[3]提供的系统级故障时间序列数据集。该数据集包含两架正在运营的波音737飞机18年（1997—2014年）的故障记录，通过整理后得到2个包含216个数据点的月度故障时间序列数据。故障时间序列如图4所示，分别对应A飞机和B飞机2个数据源，横坐标为年份，纵坐标为月度故障数。从图中可以看出，这2个系统级故障数据相比于文献[7]提供的组件级故障数据表现出更为复杂的曲线形态。此外，对于复杂系统来说，一定时期内发生的故障数可以视为系统的平均故障率[27]，用公式表示为  $\lambda_{\mathrm{a}} = \sum_{i = 1}^{N}f_{i} / \sum_{i = 1}^{N}t_{i} = 1 / \mathrm{MTBF}$ ，其中  $f_{i}$  和  $t_{i}$  分别为第  $i$  次使用周期中发生的故障数和工作时长，  $N$  为指定时期内的工作次数，MTBF（Mean Time BetweenFailure）为平均故障间隔时间。因此，本文选择故障数这一重要的可靠性指标作为实验对象，并设定前17年的204个数据点作为训练集，第18年的12个数据点作为测试集。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/bf7485617b8f183c5b1b99ea7fa700ba53c3b96bec0d6ae90f4ce01c71be76aa.jpg)  
图4A、B飞机的月度故障时间序列数据 Fig.4 Monthly failure time series data for Aircraft A and Aircraft B

# 3.1.2 对比模型

除了第1节提到的RNN和GRU模型，本文将LSTM模型与以下5种时间序列预测模型进行实验对比。

# 1）Holt-Winters模型

Holt- Winters又称3次指数平滑，是一种能够处理含有趋势性和周期性成分的时间序列分析方法[28]。其思想是利用历史数据的不同特征成分（水平、趋势和季节）来递推当前数据。Holt- Winters模型的重要参数是与特征成分对应的3个平滑系数，即  $\alpha ,\beta$  和  $\gamma$ ，取值均为0到1之间，且越靠近1则预测结果越依赖于近期观测值。此外，根据季节性成分在递推公式中的不同组织形式，Holt- Winters模型又分为加法和乘法2种类型（分

别表示为 Holt- Wintersa 和 Holt- Wintersm）。在实际使用中，这2种类型均需要计算不同特征成分的初始值，并根据均方误差最小来计算3个平滑系数。

# 2）自回归移动平均

ARIMA是时间序列分析的经典理论和方法，其模型可以表示为ARIMA  $(p,d,q)$  ，其中  $p\cdot d\cdot q$  分别为自回归项数、差分次数、移动平均项数[29]。在实际使用中，这3个参数可以通过观测自相关函数（Auto Correlation Function，ACF）和偏自相关函数（Partial Auto Correlation Function，PACF）确定，也可以通过计算AIC（Akaike Information Criterion）或BIC（Bayesian Information Criterion）值取其最小来确定。本文采用了文献[30]提出的自动化方法建立ARIMA模型。

# 3）奇异谱分析

SSA是一种时域和频域相结合的非参数方法，可以用于处理非线性、非平稳以及包含噪声的时间序列，其核心思想是提取序列中的有效成分建模和预测[3]。SSA包括分解和重构2个过程，其中分解过程又包括嵌入和奇异值分解（SingularValueDecomposition，SVD)2个子过程，重构过程又包括分组和对角平均2个子过程。在实际使用中，需要确定的2个参数为嵌入子过程的窗口长度  $L_{\mathrm{ssai}}$  和分组子过程的分组类别  $G_{\mathrm{ssa}}$  。本文根据文献[32]提出的方法确定这2个参数的取值范围并取其最大值。此外，SSA包含递归和向量2种预测方法（分别表示为  $\mathrm{SSA}^{\mathrm{T}}$  和  $\mathrm{SSA}^{\mathrm{v}}$  )，其中向量预测方法拥有更好的稳定性但是需要消耗更多的计算资源。

# 4）多元线性回归

多元线性回归（MultipleLinearRegression，MLR)是一种广泛应用于预测任务的多因素分析方法[33]。MLR用于时间序列预测的模型可以表示为  $Y_{t} = a_{0} + a_{1}Y_{t - 1} + a_{2}Y_{t - 2} + \dots +a_{k}Y_{t - k} + e$  其中：  $Y_{t}$  为  $t$  时刻的预测值，  $a_1,a_2,\dots ,a_k$  为不同历史时刻数据  $Y_{t - 1},Y_{t - 2},\dots ,Y_{t - k}$  对应的回归系数， $a_0$  和  $e$  分别为偏置项和误差项[34]。当连续的历史时刻数据被选为多因素变量时，  $k$  也可以称为窗口长度（表示为  $L_{\mathrm{mlr}}$  ）。本文选定连续2年的月度故障数据点个数24作为  $k$  的取值。

# 5）支持向量回归

SVR是一种可以用于时间序列预测的机器学习方法[35]。这种方法通过一个非线性核函数将多维输入映射到更高维度的特征空间后执行回归运算，进而得到与输出指标的非线性映射关系。

本文选择常用的高斯径向基函数（GaussianRadialBasisFunction，RBI）作为非线性核函数，并采用文献[36]提出的启发式方法计算核函数参数  $\sigma_{\mathrm{svr}}$  和误差边界  $\epsilon$  。此外，SVR模型的惩罚因子  $C$  和窗口长度  $L_{\mathrm{svr}}$  分别设置为3和24。

# 3.1.3 度量指标

本文从以下2个方面评价所有的预测模型：计算耗时和模型精度。对于计算耗时，本文统计了每个模型在构建过程中消耗的时间；对于模型精度，本文选择均方根误差（RootMeanSquareError，RMSE）作为度量标准。RMSE的计算公式可以表示为RMSE  $= \sqrt{\sum_{t = 1}^{T}\left(y_{t} - f_{t}\right)^{2} / T}$  ，其中，  $f_{t}$  和  $y_{t}$  分别为故障时间序列在  $t$  时刻的观测值和模型输出值，  $T$  为数据点个数。本文通过对训练集和测试集分别计算RMSE值来定量地评价模型的拟合和预测精度。

# 3.1.4 平台和环境

实验所使用计算机的配置如下：处理器为英特尔酷睿DuoCPU5- 6500，CPU频率为  $3.20\mathrm{GHz}$  和  $3.19\mathrm{GHz}$  ；内存为  $4.00\mathrm{GB}$  ；操作系统为Windows10（64位）；程序设计语言为Python3.5.2(64位）和R3.3.3（64位）；集成开发环境为Py- CharmCommunityEdition2016.3.2和Rstudio0.99.903。程序设计过程中，RNN、LSTM和GRU模型由Python的tensorflow  $0.12.0\mathrm{rc}0^{[37]}$  程序包实现，Holt- Winters、ARIMA、SSA、MLR和SVR模型由R的stats3.3.3[38]、forecast8.0[39]、Rssa0.14[40]和rminer1.4.2[41]程序包实现。

# 3.2 实验结果

首先，以飞机A为例，应用2.1节提出的方法对标准化后的故障时间序列训练集建立LSTM预测模型。这里初步根据经验确定模型参数，分割窗口长度  $L$  取最小值2，状态向量大小  $S_{\mathrm{state}}$  取半年的月度故障数据点个数6，随机种子数seed  $=$  1，训练步数steps  $= 500$  。图5展示了相同参数下不同学习率  $(\eta = 0.05,0.1,0.5)$  训练LSTM模型的损失变化和模型精度。可以看出：当  $\eta = 0.05$  和  $\eta = 0.1$  时，最终获得的损失较小（0.83左右）；3个学习率对应的训练集拟合精度基本相同（RMSE值在2.0附近）；在3、4、5、6和12个测试点上，  $\eta = 0.1$  的预测精度最高（RMSE值最低）。因此，本文选定  $\eta = 0.1$  训练LSTM模型。

为了验证LSTM模型在不同类型循环神经网络中的优势，本文将LSTM模型的隐藏层细胞替换为RNN和GRU结构，并以相同参数进行实验。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/0e7d223562e96d91f90ee9b3f0153c4219cc5cf85dbb001847b54e52c9a6f99e.jpg)  
图5 不同学习率的损失变化和模型精度对比（A飞机） Fig.5 Comparison of loss change and model accuracy with different learning rates (Aircraft A)

实验结果如图6所示。从图中可以看出：LSTM和GRU的损失变化相似并且都优于RNN，对应的训练集拟合精度也较高；在5.6和12个测试点上，LSTM的预测精度要高于RNN和GRU。

为了进一步验证LSTM模型的应用效果，本文采用不同的时间序列预测模型进行对比，实验结果如表1所示。从表中可以看出：LSTM模型的拟合精度要低于SSA和SVR模型，但是高于其他6种模型；LSTM模型的整体预测精度较高，在6和12个测试点上的预测精度最高（RMSE值分别达到了2.109和2.196）；LSTM模型在该参数组合下的计算耗时要少于AHIMA模型，但是多于其他8种模型。

对于B飞机，实验流程与A飞机类似。这里根据经验调整模型参数，令状态向量大小  $S_{\mathrm{state}}$  仍

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/89a4f0c9da20ec0a01d03d7d9bc252bac15dc337f49d1e7bd44123e782fd0514.jpg)  
图6 不同隐藏层细胞的损失变化和模型精度对比（学习率  $\eta = 0.1$  ，A飞机） Fig.6 Comparison of loss change and model accuracy with different hidden layer cells (learning rate  $\eta = 0.1$  ，Aircraft A)

然取6，分割窗口长度  $\mathcal{E}$  取一年的月度故障数据点个数12，随机种子数  $\mathrm{seed} = 100$  ，训练步数 $\mathrm{steps} = 1000$  。图7展示了相同参数下不同学习率 $(\eta = 0.01,0.03,0.05)$  训练LSTM模型的损失变化和模型精度。可以看出：3个学习率对应的训练集拟合精度基本相同（RMSE值在1.2附近）； $\eta = 0.05$  时存在一定的过拟合现象，导致预测精度波动较大；在6和12个测试点上，  $\eta = 0.03$  的预测精度最高（RMSE值最低）。因此，本文选定 $\eta = 0.03$  训练LSTM模型。

接下来，本文替换隐藏层细胞为RNN和GRU结构并进行实验，结果如图8所示。可以看出，LSTM模型无论是在损失变化还是整体模型

表1不同预测模型实验结果对比（A飞机）

Table 1 Experimental results for different prediction models (Aircraft A)  

<table><tr><td rowspan="2">模型</td><td rowspan="2">模型参数</td><td rowspan="2">训练集
拟合
RMSE 值</td><td colspan="5">测试集预测 RMSE 值</td><td rowspan="2">耗时 /s</td></tr><tr><td>1个
测试点</td><td>2个
测试点</td><td>3个
测试点</td><td>6个
测试点</td><td>12个
测试点</td></tr><tr><td>Holt-Wintersa</td><td>α=0.044,β=0.073,γ=0.223</td><td>2.617</td><td>0.088</td><td>0.069</td><td>2.278</td><td>2.882</td><td>2.595</td><td>0.02</td></tr><tr><td>Holt-Wintersm</td><td>α=0,β=0,γ=0.6</td><td>3.199</td><td>1.704</td><td>1.205</td><td>2.837</td><td>3.179</td><td>3.066</td><td>0.02</td></tr><tr><td>ARIMA</td><td>p=2,d=1,q=2</td><td>2.329</td><td>1.475</td><td>1.224</td><td>2.712</td><td>2.832</td><td>2.509</td><td>1.53</td></tr><tr><td>SSA&#x27;</td><td>Lss=96,Gss=list(1:50)</td><td>0.770</td><td>2.487</td><td>1.781</td><td>1.871</td><td>2.437</td><td>2.622</td><td>0.02</td></tr><tr><td>SSA&quot;</td><td>Lss=96,Gss=list(1:50)</td><td>0.770</td><td>2.509</td><td>1.843</td><td>2.175</td><td>2.500</td><td>2.295</td><td>0.02</td></tr><tr><td>MLR</td><td>LMLR=24</td><td>2.221</td><td>2.490</td><td>1.773</td><td>2.602</td><td>2.617</td><td>2.381</td><td>0.02</td></tr><tr><td>SVR</td><td>Lsvr=24,C=3,g=0.289,σsvr=0.023</td><td>1.167</td><td>1.740</td><td>1.526</td><td>1.967</td><td>2.139</td><td>2.321</td><td>0.03</td></tr><tr><td>RNN</td><td>L=2,Sstate=6,seed=1,steps=500,η=0.1</td><td>2.183</td><td>1.716</td><td>1.225</td><td>1.995</td><td>2.528</td><td>2.595</td><td>0.61</td></tr><tr><td>GRU</td><td>L=2,Sstate=6,seed=1,steps=500,η=0.1</td><td>1.982</td><td>1.921</td><td>1.651</td><td>2.520</td><td>2.691</td><td>2.248</td><td>0.78</td></tr><tr><td>LSTM</td><td>L=2,Sstate=6,seed=1,steps=500,η=0.1</td><td>1.962</td><td>1.919</td><td>1.577</td><td>2.745</td><td>2.109</td><td>2.196</td><td>0.81</td></tr></table>

注：最小RMSE值和最小耗时由下划线标记。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/a7924794d857b265811e0b70f4a7ed8330c733d648bc7da429f8ca7103c3d693.jpg)  
图7 不同学习率的损失变化和模型精度对比（B飞机）

Fig.7 Comparison of loss change and model accuracy with different learning rates (Aircraft B)

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/dcf5ed190f3b061a922a51ddcf39533773923835872b057e446760485a89d76d.jpg)  
图8 不同隐藏层细胞的损失变化和模型精度对比（学习率  $\eta = 0.03$  ，B飞机）

Fig.8 Comparison of loss change and model accuracy with different hidden layer cells (learning rate  $\eta = 0.03$  ，Aircraft B)

精度上都优于RNN和GRU模型。图9展示了LSTM模型的拟合（图9（a））和预测（图9（b））结果，其中黑色线条分别代表原始故障时间序列数据划分的训练集和测试集，灰色线条分别代表LSTM模型在训练集和测试集上的拟合序列和预测序列。从图中可以看出，在12个测试点上，LSTM模型很好地跟踪了真实的故障数据，达到了比较理想的预测效果。

最后，LSTM模型和不同时间序列预测模型的实验对比结果如表2所示。从表中可以看出：LSTM模型的拟合精度要低于SSA模型，但是高

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/c052bfbbc3a346d2cf966065c73c108a97a893035cfe8e366119f6bf8832ed0a.jpg)  
图9 LSTM模型的拟合和预测结果（学习率  $\eta = 0.03$  ，B飞机）Fig.9 Fitting and forecasting results with LSTM model (learning rate  $\eta = 0.03$  ，Aircraft B)

于其他7种模型；LSTM模型的整体预测精度较高，在3、6、12个测试点上的预测精度最高（RMSE值分别达到了1.703、1.237和1.580）；RNN、GRU和LSTM模型在该参数组合下的计算耗时要明显多于其他7种模型，并且以LSTM模型耗时最多。

# 3.3 参数优选

在3.2节的实验中，LSTM模型的参数取值主要是通过经验来确定的。本节应用2.2节提到的多层网格搜索算法，对LSTM模型的3个关键参数进行优选。首先，固定非关键参数取值：随机种子数  $\mathrm{seed} = 1$  ，训练步数  $\mathrm{steps} = 500$  ；然后，设定3个参数的取值范围：分割窗口长度  $L\in \{2$ $3,\dots ,24\}$  ，状态向量大小  $S_{\mathrm{state}}\in \{2,3,\dots ,24\}$  ，学习率  $\eta \in \{0.001,0.003,0.005,0.01,0.03,0.05\}$  其中  $L$  和  $S_{\mathrm{state}}$  的搜索步长为1；最后，设置目标函数为12个测试点上预测精度最高（RMSE值最小），应用2.2节中的算法2进行网格搜索。

图10和图11分别展示了针对2个数据源（A飞机和B飞机）建立2.1节提到的LSTM预测模型的参数搜索结果。在每个子图中，横坐标为分割窗口长度  $L$  ，纵坐标为状态向量大小  $S_{\mathrm{state}}$ $\mathrm{Rm}$  为最小RMSE值；不同子图对应学习率  $\eta$  的不同取值；网格中的方块面积越大、颜色越深表示RMSE值越小。从图10和图11中可以看出，当  $L$  和  $S_{\mathrm{state}}$  取值较小时更容易获得较高的预测精度。表3和表4分别列出了针对2个数据源的前5组最优参数组合以及对应的模型精度。表1和表2对比可知，优选后的LSTM模型精度明显提高。

表2不同预测模型实验结果对比（B飞机）

Table 2 Experimental results for different prediction models (Aircraft B)  

<table><tr><td rowspan="2">模型</td><td rowspan="2">模型参数</td><td rowspan="2">训练集
拟合
RMSE值</td><td colspan="5">测试集预测RMSE值</td><td rowspan="2">耗时/s</td></tr><tr><td>1个
测试点</td><td>2个
测试点</td><td>3个
测试点</td><td>4个
测试点</td><td>5个
测试点</td></tr><tr><td>Holt-Wintersa</td><td>α=0.011,β=0.210,γ=0.191</td><td>2.907</td><td>1.749</td><td>3.605</td><td>3.353</td><td>2.609</td><td>2.474</td><td>0.02</td></tr><tr><td>Holt-Wintersm</td><td>α=0,β=0,γ=0.438</td><td>3.231</td><td>1.837</td><td>4.252</td><td>3.807</td><td>2.950</td><td>2.816</td><td>0.02</td></tr><tr><td>ARIMA</td><td>p=4,d=1,q=1</td><td>2.565</td><td>1.719</td><td>2.079</td><td>2.566</td><td>2.091</td><td>2.021</td><td>1.77</td></tr><tr><td>SSA&#x27;</td><td>Lssa=96,Gssa=list(1:50)</td><td>0.853</td><td>0.178</td><td>2.142</td><td>1.768</td><td>4.289</td><td>5.023</td><td>0.02</td></tr><tr><td>SSA&#x27;</td><td>Lssa=96,Gssa=list(1:50)</td><td>0.853</td><td>0.730</td><td>1.686</td><td>1.987</td><td>2.904</td><td>3.161</td><td>0.02</td></tr><tr><td>MLR</td><td>Lmlr=24</td><td>2.547</td><td>1.729</td><td>2.026</td><td>2.912</td><td>2.418</td><td>2.360</td><td>0.02</td></tr><tr><td>SVR</td><td>Lsvr=24,C=3,ε=0.252,σsvr=0.023</td><td>1.353</td><td>0.241</td><td>1.374</td><td>2.893</td><td>2.278</td><td>2.121</td><td>0.03</td></tr><tr><td>RNN</td><td>L=12,Sstate=6,seed=100,steps=1000,η=0.03</td><td>2.058</td><td>0.828</td><td>2.630</td><td>2.556</td><td>2.484</td><td>2.671</td><td>3.13</td></tr><tr><td>GRU</td><td>L=12,Sstate=6,seed=100,steps=1000,η=0.03</td><td>1.559</td><td>1.696</td><td>1.257</td><td>3.525</td><td>2.815</td><td>2.690</td><td>5.36</td></tr><tr><td>LSTM</td><td>L=12,Sstate=6,seed=100,steps=1000,η=0.03</td><td>1.276</td><td>0.956</td><td>1.691</td><td>1.703</td><td>1.237</td><td>1.580</td><td>5.64</td></tr></table>

注：最小RMSE值和最小耗时由下划线标记。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/e41a52618efdb4aeb0111c4afa61778e95cf29acc5796850b19ee87b46363dba.jpg)  
图10 LSTM模型3参数多层网格搜索结果（A飞机）

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-13/66f5f352-d13b-43eb-a0ef-6822867789f5/1d09a12f21eaf74be6bae7a473a04bd454034c4cc71aada51aa24b7a8ef6eade.jpg)  
Fig.10 Multilayer grid search results for three parameters of LSTM model (Aircraft A)  图11 LSTM模型3参数多层网格搜索结果（B飞机） Fig.11 Multilayer grid search results for three parameters of LSTM model (Aircraft B)

表4LSTM模型前5组最优参数组合以及对应的模型精度（B飞机）

Table 4 The first five groups of optimal parameters and corresponding model accuracy for LSTM model (Aircraft B)  
表3LSTM模型前5组最优参数组合以及对应的模型精度（A飞机）

Table 3 The first five groups of optimal parameters andcorresponding model accuracy for LSTM model (Aircraft A)  

<table><tr><td rowspan="2">排 名</td><td colspan="3">模型参数</td><td>训练集</td><td colspan="5">测试集预测RMSE值</td><td rowspan="2">耗时/s</td></tr><tr><td>L</td><td>Sstate</td><td>η</td><td>拟合RMSE值</td><td colspan="5">1个测试点2个测试点3个测试点4个测试点12个测试点</td></tr><tr><td>1</td><td>3</td><td>21</td><td>0.005</td><td>1.261</td><td>0.694</td><td>0.921</td><td>1.261</td><td>1.154</td><td>1.676</td><td>1.56</td></tr><tr><td>2</td><td>14</td><td>10</td><td>0.03</td><td>0.321</td><td>2.539</td><td>1.834</td><td>2.506</td><td>2.390</td><td>1.909</td><td>3.63</td></tr><tr><td>3</td><td>17</td><td>8</td><td>0.005</td><td>1.311</td><td>1.923</td><td>1.824</td><td>2.137</td><td>2.044</td><td>2.041</td><td>3.94</td></tr><tr><td>4</td><td>19</td><td>11</td><td>0.03</td><td>0.289</td><td>0.054</td><td>0.762</td><td>1.290</td><td>2.058</td><td>2.061</td><td>4.84</td></tr><tr><td>5</td><td>4</td><td>16</td><td>0.03</td><td>0.584</td><td>3.860</td><td>2.759</td><td>2.395</td><td>1.991</td><td>2.081</td><td>1.66</td></tr></table>

<table><tr><td rowspan="2">排 名</td><td colspan="3">模型参数</td><td>训练集</td><td colspan="5">测试集预测RMSE值</td><td rowspan="2">耗时/s</td></tr><tr><td>L</td><td>Sstate</td><td>η</td><td>拟合RMSE值</td><td colspan="5">1个测试点2个测试点3个测试点4个测试点11个测试点12个测试点</td></tr><tr><td>1</td><td>10</td><td>7</td><td>0.005</td><td>1.794</td><td>1.703</td><td>1.209</td><td>1.005</td><td>0.942</td><td>0.864</td><td>2.55</td></tr><tr><td>2</td><td>3</td><td>18</td><td>0.003</td><td>2.288</td><td>0.833</td><td>1.398</td><td>1.162</td><td>1.227</td><td>1.571</td><td>1.44</td></tr><tr><td>3</td><td>19</td><td>18</td><td>0.005</td><td>0.945</td><td>0.495</td><td>1.804</td><td>2.206</td><td>2.093</td><td>1.636</td><td>5.95</td></tr><tr><td>4</td><td>3</td><td>13</td><td>0.003</td><td>1.978</td><td>0.306</td><td>1.400</td><td>1.517</td><td>1.300</td><td>1.647</td><td>1.31</td></tr><tr><td>5</td><td>3</td><td>6</td><td>0.01</td><td>2.056</td><td>0.563</td><td>1.436</td><td>1.440</td><td>1.182</td><td>1.647</td><td>0.97</td></tr></table>

# 4结论

本文提出了基于LSTM循环神经网络的系统级故障时间序列预测方法，包括对LSTM模型的训练、预测以及参数优选等内容。实验验证表明：

1）与典型的时间序列预测模型相比，LSTM模型的拟合和预测性能整体更优。

2）LSTM模型在训练过程中的损失变化和模型精度对学习率的取值较为敏感，过低或过高的学习率可能会导致欠拟合或过拟合问题，影响模型的预测性能。

3）与其他类型的循环神经网络（RNN和GRU）相比，LSTM模型的拟合和预测精度整体更高，但是训练过程的耗时也更多。

4）基于多层网格搜索的参数优选算法效果显著，特别是对于第2个数据源（AI飞机），在测试点12上的预测精度（RMSE值）达到了0.864，而文献[8]中提出的混合模型其最优RMSE值仅为1.879。

总的来说，本文验证了LSTM模型在可靠性预测领域中的适用性，扩展了深度学习技术的应用范畴。基于目前的工作，后续可以展开进一步研究：比如扩展隐藏层层数，检验多隐藏层LSTM网络结构的应用效果；或者从众多LSTM模型参数入手，寻求更有效的参数优化方法。此外，本文是从历史数据出发，应用数据驱动的技术逆向建立预测模型。下一步，可以从可靠性相关的领域知识出发，应用提取出来的关键特征和要素正向

研究可靠性预测方法。

致谢感谢任健老师在实验数据方面提供的支持，感谢王森章博士在语言方面给予的帮助，感谢评论文的各位专家。

# 参考文献（References）

[1] VICHARE N M, PECHT M G. Prognostics and health management of electronics [J]. IEEE Transactions on Components & Packaging Technologies, 2006, 29(1):222- 229. [2] SAPANKEVYCH N, SANKAR R. Time series prediction using support vector machines: A survey [J]. IEEE Computational Intelligence Magazine, 2009, 4(2):24- 38. [3] 王鑫，吴际，刘超，等. 奇异谱分析在故障时间序列分析中的应用 [J]. 北京航空航天大学学报，2016, 42(11):2321- 2331. WANG X, WU J, LIU C, et al. Application of singular spectrum analysis for failure time series [J]. Journal of Beijing University of Aeronautics and Astronautics, 2016, 42(11):2321- 2331 (in Chinese).[4] 李瑞莹，康锐. 基于ARMA模型的故障率预测方法研究 [J]. 系统工程与电子技术, 2008, 30(6):1568- 1591. LI R Y, KANG R. Research on failure rate forecasting method based on ARMA model [J]. Systems Engineering and Electronics, 2008, 30(8):1588- 1591 (in Chinese).[5] ROCCO S C M. Singular spectrum analysis and forecasting of failure time series [J]. Reliability Engineering & System Safety, 2013, 114(6):126- 136. [6] MOURA M D C, ZIO E, LINS I D, et al. Failure and reliability prediction by support vector machines regression of time series data [J]. Reliability Engineering & System Safety, 2011, 96(11):1527- 1534. [7] XU K, XIE M, TANG L C, et al. Application of neural networks

in forecasting engine systems reliability [J]. Applied Soft Computing,2003,2(4):255- 268. [8] WANG X, WU J, LIU C, et al. A hybrid model based on singular spectrum analysis and support vector machines regression for failure time series prediction [J]. Quality & Reliability Engineering International,2016,32(8):2717- 2738. [9] LECUN Y, BENGIO Y, HINTON G. Deep learning [J]. Nature, 2015,521 (7553):436- 444. [10] GRAVES A. Long short- term memory [M]. Berlin: Springer, 2012:1735- 1780. [11] SRIVASTAVA N, MANSIMOV E, SALAKHUTDINOV R. Unsupervised learning of video representations using LSTMs [C] //Proceedings of the 32nd International Conference on Machine Learning. Lille: JMLR W&CP, 2015:843- 852. [12] DONAHUE J, HENDRICKS L A, ROHRBACH M, et al. Longterm recurrent convolutional networks for visual recognition and description [J]. IEEE Transactions on Pattern Analysis & Machine Intelligence,2015,39(4):677- 691. [13] VINYALS O, TOSHEV A, BENGIO S, et al. Show and tell: A neural image caption generator [J] //IEEE Conference on Computer Vision and Pattern Recognition. Piscataway, NJ: IEEE Press,2015:3156- 3164. [14] MA X, TAO Z, WANG Y, et al. Long short- term memory neural network for traffic speed prediction using remote microwave sensor data [J]. Transportation Research Part C Emerging Technologies,2015,54:187- 197. [15] HANSON J, YANG Y, PALIWAL K, et al. Improving protein disorder prediction by deep bidirectional long short- term memory recurrent neural networks [J]. Bioinformatics, 2017, 33 (5):685. [16] GREFF K, SRIVASTAVA R K, KOUTNIK J, et al. LSTM: A search space odyssey [J]. IEEE Transactions on Neural Networks & Learning Systems,2016,LP(99):1- 11. [17] GRAVES A, SCHMIDHUBER J. Famewise phoneme classification with bidirectional LSTM and other neural network architectures [J]. Neural Networks,2005,18(5- 6):602. [18] AMARI S I. Backpropagation and stochastic gradient descent method [J]. Neurocomputing,1993,5(4- 5):185- 196. [19] DUCHI J, HAZAN E, SINGER Y. Adaptive subgradient methods for online learning and stochastic optimization [J]. Journal of Machine Learning Research,2011,12(7):257- 269. [20] YEUNG S, RUSSAKOVSKY O, NING J, et al. Every moment counts: Dense detailed labeling of actions in complex videos [J]. International Journal of Computer Vision,2017(8):1- 45. [21] KINGMA D P, BA J. Adam: A method for stochastic optimization [C] //ICLR 2015,2015:1- 15. [22] CHUNG J, GULCEHRE C, CHO H H, et al. Empirical evaluation of gated recurrent neural networks on sequence modeling [C] //NIPS 2014 Deep Learning and Representation Learning Workshop,2014:1- 9. [23] CHEN P W, WANG J Y, LEE H M. Model selection of SVMs using GA approach [C] //IEEE International Joint Conference on Neural Networks. Piscataway, NJ: IEEE Press, 2004: 2035- 2040. [24] BRATTON D, KENNEDY J. Defining a standard for particle swarm optimization [C] //IEEE Swarm Intelligence Symposium. Piscataway, NJ: IEEE Press, 2007:120- 127. [25] SNOEK J, LAROCHIELLE H, ADAMS R P. Practical Bayesian optimization of machine learning algorithms [C] //International Conference on Neural Information Processing Systems. Lake Tahoe: Curran Associates Inc., 2012:2951- 2959. [26] HSU C W, CHANG C C, LIN C J. A practical guide to support vector classification [EB/OL]. (2016- 05- 19) [2017- 03- 20]. https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf. [27] SU C, JIN Q, FU Y. Correlation analysis for wind speed and failure rate of wind turbines using time series approach [J]. Journal of Renewable & Sustainable Energy, 2012,4(3):687- 700. [28] CHATFIELD C. The Holt- Winters forecasting procedure [J]. Journal of the Royal Statistical Society, 1978,27(3):264- 279. [29] BARTHOLOMEW D J. Time series analysis forecasting and control [J]. Journal of the Operational Research Society, 1971, 22(2):199- 201. [30] HYNDMAN R J, KHANDAKAR Y. Automatic time series forecasting:The forecast package for R [J]. Journal of Statistical Software,2008,27(3):1- 22. [31] VAUTARD R, YIOU P, GHIL M. Singular- spectrum analysis: A toolkit for short, noise- chaotic signals [J]. Physica D- Nonlinear Phenomena,1992,58(1- 4):95- 126. [32] GOLYANDINA N, KOROBEYNIKOV A. Basic singular spectrum analysis and forecasting with R [J]. Computational Statistics & Data Analysis,2014,71(1):934- 954. [33] NIKOLOPOULOS K, GOODWIN P, PATELIS A, et al. Forecasting with cue information: A comparison of multiple regression with alternative forecasting approaches [J]. European Journal of Operational Research,2007,180(1):354- 368. [34] BIANCO V, MANCA O, NARDINI S. Electricity consumption forecasting in Italy using linear regression models [J]. Energy, 2009,34(9):1413- 1421. [35] BRERETON R G, LOYD G R. Support vector machines for classification and regression [J]. Analyst, 2010, 135(2):230- 267. [36] CHERKASSKY V, MA Y. Practical selection of SVM parameters and noise estimation in SVM regression [J]. Neural Networks,2004,17(1):113- 126. [37] Google. tensorflow miner 1.4.2 [EB/OL]. [2017- 03- 20]. https://www.tensorflow.org/versions/r0.12. [38] R Core Team. The R project for statistical computing [EB/OL]. [2017- 03- 20]. https://www.r- project.org. [39] HYNDMAN R. robjhyndman/forecast [EB/OL]. [2017- 03- 20]. https://github.com/robjhyndman/forecast. [40] KOROBEYNIKOV A. asl/rssa [EB/OL]. [2017- 03- 20]. https://github.com/asl/rssa [41] PAULO C. rminer: Data mining classification and regression methods [EB/OL]. [2017- 03- 20]. https://cran.r- project.org/package = rminer

作者简介:  王鑫 男,博士研究生。主要研究方向:数据驱动技术。

吴际 男，博士，副教授，硕士生导师。主要研究方向：模型驱动、软件可靠性分析。

刘超 男，博士，教授，博士生导师。主要研究方向：软件工程、软件测试。

# Exploring LSTM based recurrent neural network for failure time series prediction

WANG Xin $^{1}$ , WU Ji $^{1, *}$ , LIU Chao $^{1}$ , YANG Haiyan $^{1}$ , DU Yanli $^{2}$ , NIU Wensheng $^{1,3}$   (1. School of Computer Science and Engineering, Beijing University of Aeronautics and Astronautics, Beijing 100083, China; 2. Fengtai Vocational Education Central School, Beijing 100076, China; 3. Aeronautical Computing Technique Research Institute, Aviation Industry Corporation of China, Xi'an 710068, China)

Abstract: Effectively forecasting the failure data in the usage stage is essential to reasonably make reliability plans and carry out reliability maintaining activities. Beginning with the historical failure data of complex system, a long short- term memory (LSTM) based recurrent neural network for failure time series prediction is presented, in which the design of network structure, the procedures and algorithms of network training and forecasting are involved. Furthermore, a multilayer grid search algorithm is proposed to optimize the parameters of LSTM prediction model. The experimental results are compared with various typical time series prediction models, and validate that the proposed LSTM prediction model and the corresponding parameter optimization algorithm have strong adaptiveness and higher accuracy in failure time series prediction.

Keywords: long short- term memory (LSTM) model; recurrent neural network; failure time series prediction; multilayer grid search; deep learning
