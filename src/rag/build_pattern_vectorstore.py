# -*- coding: utf-8 -*-
"""
æ„å»ºä¾å­˜è·¯å¾„æ¨¡å¼çš„å‘é‡æ•°æ®åº“
ä½¿ç”¨ BGE-large-zh-v1.5 + ChromaDB
"""
import os
import sys
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

import torch
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

print("=" * 80)
print("ğŸ”§ PHM ä¾å­˜è·¯å¾„æ¨¡å¼å‘é‡æ•°æ®åº“æ„å»ºå·¥å…·")
print("=" * 80)

# ==================== é…ç½®éƒ¨åˆ† ====================

# è·¯å¾„é…ç½®
CSV_FILE = PROJECT_ROOT / "data" / "processed" / "dependency_patterns" / "semantic_syntactic_patterns_report_2025-10-14_172830.csv"
CHROMA_DB_DIR = PROJECT_ROOT / "data" / "vectorstores" / "pattern_chroma_db"
COLLECTION_NAME = "phm_dependency_patterns"

# æ¨¡å‹é…ç½®
EMBEDDING_MODEL = "BAAI/bge-large-zh-v1.5"
BATCH_SIZE = 32  # æ‰¹é‡ç¼–ç å¤§å°ï¼ˆæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼‰

# å°è§„æ¨¡æµ‹è¯•æ¨¡å¼ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
TEST_MODE = os.getenv("TEST_MODE", "0") == "1"
TEST_SAMPLE_SIZE = 20  # æµ‹è¯•æ—¶åªå¤„ç†å‰ N æ¡

# ==================== å·¥å…·å‡½æ•° ====================

def check_gpu():
    """æ£€æŸ¥ GPU å¯ç”¨æ€§"""
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"âœ… æ£€æµ‹åˆ° GPU: {gpu_name} ({gpu_memory:.2f} GB)")
        return True
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        return False

def load_patterns_from_csv(csv_path: Path) -> pd.DataFrame:
    """ä» CSV åŠ è½½ä¾å­˜è·¯å¾„æ¨¡å¼"""
    print(f"\nğŸ“‚ åŠ è½½ä¾å­˜è·¯å¾„æ¨¡å¼: {csv_path}")
    
    if not csv_path.exists():
        raise FileNotFoundError(f"CSV æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
    
    # è¯»å– CSVï¼ˆå‡è®¾åˆ—åä¸º: è¯­ä¹‰æ¨¡å¼, æ€»é¢‘æ¬¡, å¥æ³•å®ç°è·¯å¾„ï¼‰
    df = pd.read_csv(csv_path)
    
    print(f"âœ… åŠ è½½æˆåŠŸ: {len(df)} æ¡æ¨¡å¼")
    print(f"   åˆ—å: {list(df.columns)}")
    
    # æ ‡å‡†åŒ–åˆ—åï¼ˆå…¼å®¹å¸¦/ä¸å¸¦è‹±æ–‡æ³¨é‡Šçš„åˆ—åï¼‰
    column_mapping = {}
    for col in df.columns:
        if "è¯­ä¹‰æ¨¡å¼" in col:
            column_mapping[col] = "è¯­ä¹‰æ¨¡å¼"
        elif "æ€»é¢‘æ¬¡" in col or "é¢‘æ¬¡" in col:
            column_mapping[col] = "æ€»é¢‘æ¬¡"
        elif "å¥æ³•" in col and "è·¯å¾„" in col:
            column_mapping[col] = "å¥æ³•å®ç°è·¯å¾„"
    
    df = df.rename(columns=column_mapping)
    print(f"   æ ‡å‡†åŒ–ååˆ—å: {list(df.columns)}")
    
    # æ£€æŸ¥å¿…è¦åˆ—
    required_cols = ["è¯­ä¹‰æ¨¡å¼", "æ€»é¢‘æ¬¡", "å¥æ³•å®ç°è·¯å¾„"]
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        raise ValueError(f"CSV ç¼ºå°‘å¿…è¦åˆ—: {missing}ï¼Œå½“å‰åˆ—: {list(df.columns)}")
    
    return df

def prepare_documents(df: pd.DataFrame, test_mode: bool = False) -> List[Dict[str, Any]]:
    """å‡†å¤‡æ–‡æ¡£åˆ—è¡¨ï¼ˆç”¨äºå‘é‡åŒ–å’Œå­˜å‚¨ï¼‰"""
    print(f"\nğŸ“ å‡†å¤‡æ–‡æ¡£...")
    
    if test_mode:
        df = df.head(TEST_SAMPLE_SIZE)
        print(f"âš ï¸ æµ‹è¯•æ¨¡å¼ï¼šä»…å¤„ç†å‰ {TEST_SAMPLE_SIZE} æ¡")
    
    documents = []
    for idx, row in df.iterrows():
        # æ„å»ºæ–‡æ¡£å†…å®¹ï¼ˆç”¨äºå‘é‡åŒ–ï¼‰
        # ç­–ç•¥ï¼šç»“åˆè¯­ä¹‰æ¨¡å¼å’Œå¥æ³•è·¯å¾„ï¼Œæä¾›æ›´ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯
        content = f"{row['è¯­ä¹‰æ¨¡å¼']} | å¥æ³•è·¯å¾„: {row['å¥æ³•å®ç°è·¯å¾„']}"
        
        # å…ƒæ•°æ®ï¼ˆç”¨äºæ£€ç´¢åçš„ä¿¡æ¯å±•ç¤ºï¼‰
        metadata = {
            "pattern_id": str(idx),
            "semantic_pattern": row['è¯­ä¹‰æ¨¡å¼'],
            "syntactic_path": row['å¥æ³•å®ç°è·¯å¾„'],
            "frequency": int(row['æ€»é¢‘æ¬¡']),
            "created_at": datetime.now().isoformat()
        }
        
        documents.append({
            "id": f"pattern_{idx}",
            "content": content,
            "metadata": metadata
        })
    
    print(f"âœ… å‡†å¤‡å®Œæˆ: {len(documents)} ä¸ªæ–‡æ¡£")
    return documents

def create_embeddings(documents: List[Dict[str, Any]], model: SentenceTransformer, batch_size: int = 32):
    """æ‰¹é‡ç”Ÿæˆ embeddings"""
    print(f"\nğŸ”„ ç”Ÿæˆå‘é‡è¡¨ç¤º...")
    print(f"   - æ‰¹é‡å¤§å°: {batch_size}")
    print(f"   - æ–‡æ¡£æ•°é‡: {len(documents)}")
    
    contents = [doc["content"] for doc in documents]
    
    # æ‰¹é‡ç¼–ç ï¼ˆæ˜¾ç¤ºè¿›åº¦æ¡ï¼‰
    embeddings = model.encode(
        contents,
        batch_size=batch_size,
        show_progress_bar=True,
        convert_to_numpy=True
    )
    
    print(f"âœ… å‘é‡ç”Ÿæˆå®Œæˆ")
    print(f"   - å‘é‡ç»´åº¦: {embeddings.shape[1]}")
    print(f"   - å‘é‡æ•°é‡: {embeddings.shape[0]}")
    
    if torch.cuda.is_available():
        print(f"   - GPU æ˜¾å­˜å³°å€¼: {torch.cuda.max_memory_allocated(0) / 1024**3:.2f} GB")
    
    return embeddings

def build_chromadb(documents: List[Dict[str, Any]], embeddings, db_dir: Path, collection_name: str):
    """æ„å»º ChromaDB å‘é‡æ•°æ®åº“"""
    print(f"\nğŸ’¾ æ„å»º ChromaDB å‘é‡æ•°æ®åº“...")
    print(f"   - å­˜å‚¨è·¯å¾„: {db_dir}")
    print(f"   - Collection: {collection_name}")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    db_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯
    client = chromadb.PersistentClient(
        path=str(db_dir),
        settings=Settings(
            anonymized_telemetry=False,
            allow_reset=True
        )
    )
    
    # åˆ é™¤æ—§ collectionï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    try:
        client.delete_collection(name=collection_name)
        print("   â„¹ï¸ å·²åˆ é™¤æ—§ collection")
    except Exception:
        pass
    
    # åˆ›å»ºæ–° collection
    collection = client.create_collection(
        name=collection_name,
        metadata={
            "description": "PHM ä¾å­˜è·¯å¾„æ¨¡å¼å‘é‡åº“",
            "embedding_model": EMBEDDING_MODEL,
            "created_at": datetime.now().isoformat()
        }
    )
    
    # æ·»åŠ æ–‡æ¡£å’Œå‘é‡
    collection.add(
        ids=[doc["id"] for doc in documents],
        embeddings=embeddings.tolist(),
        documents=[doc["content"] for doc in documents],
        metadatas=[doc["metadata"] for doc in documents]
    )
    
    print(f"âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆ")
    print(f"   - æ€»æ¡ç›®æ•°: {collection.count()}")
    
    return collection

def test_retrieval(collection, model: SentenceTransformer):
    """æµ‹è¯•æ£€ç´¢åŠŸèƒ½"""
    print(f"\nğŸ” æµ‹è¯•æ£€ç´¢åŠŸèƒ½...")
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "æ·±åº¦å­¦ä¹ æ¨¡å‹é¢„æµ‹è®¾å¤‡æ•…éšœ",
        "ä¼ æ„Ÿå™¨æ•°æ®ç”¨äºå¥åº·ç›‘æµ‹",
        "ç®—æ³•æå‡è¯Šæ–­å‡†ç¡®ç‡"
    ]
    
    for query in test_queries:
        print(f"\n   æŸ¥è¯¢: {query}")
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = model.encode([query], convert_to_numpy=True)
        
        # æ£€ç´¢ Top 3
        results = collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=3
        )
        
        print(f"   Top 3 ç›¸ä¼¼æ¨¡å¼:")
        for i, (doc, meta, dist) in enumerate(zip(
            results['documents'][0],
            results['metadatas'][0],
            results['distances'][0]
        ), 1):
            print(f"      {i}. [{meta['semantic_pattern']}] (è·ç¦»: {dist:.3f})")
            print(f"         é¢‘æ¬¡: {meta['frequency']}, å¥æ³•: {meta['syntactic_path']}")

# ==================== ä¸»æµç¨‹ ====================

def main():
    print(f"\nå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. æ£€æŸ¥ GPU
    has_gpu = check_gpu()
    
    # 2. åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¥ åŠ è½½ Embedding æ¨¡å‹: {EMBEDDING_MODEL}")
    model = SentenceTransformer(EMBEDDING_MODEL)
    
    if has_gpu:
        model = model.to('cuda')
        print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ° GPU")
    else:
        print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ° CPU")
    
    # 3. åŠ è½½ CSV æ•°æ®
    df = load_patterns_from_csv(CSV_FILE)
    
    # 4. å‡†å¤‡æ–‡æ¡£
    documents = prepare_documents(df, test_mode=TEST_MODE)
    
    # 5. ç”Ÿæˆ embeddings
    embeddings = create_embeddings(documents, model, batch_size=BATCH_SIZE)
    
    # 6. æ„å»º ChromaDB
    collection = build_chromadb(documents, embeddings, CHROMA_DB_DIR, COLLECTION_NAME)
    
    # 7. æµ‹è¯•æ£€ç´¢
    test_retrieval(collection, model)
    
    print("\n" + "=" * 80)
    print("âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼")
    print("=" * 80)
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - æ¨¡å¼æ€»æ•°: {len(documents)}")
    print(f"   - å‘é‡ç»´åº¦: {embeddings.shape[1]}")
    print(f"   - å­˜å‚¨è·¯å¾„: {CHROMA_DB_DIR}")
    print(f"   - Collection: {COLLECTION_NAME}")
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print(f"   ä»å…¶ä»–è„šæœ¬åŠ è½½:")
    print(f"   ```python")
    print(f"   import chromadb")
    print(f"   client = chromadb.PersistentClient(path='{CHROMA_DB_DIR}')")
    print(f"   collection = client.get_collection('{COLLECTION_NAME}')")
    print(f"   ```")
    print(f"\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()
