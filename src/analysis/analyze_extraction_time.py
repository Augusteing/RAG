"""
åˆ†æä¸åŒæ¨¡å‹çš„çŸ¥è¯†æŠ½å–æ—¶é—´ç»Ÿè®¡

åŠŸèƒ½ï¼š
1. è¯»å–å„æ¨¡å‹çš„extraction_logæ—¥å¿—æ–‡ä»¶
2. ç»Ÿè®¡æ¯ç¯‡è®ºæ–‡çš„æŠ½å–æ—¶é—´
3. ç”Ÿæˆæ¯ä¸ªæ¨¡å‹çš„è®ºæ–‡çº§æ—¶é—´ç»Ÿè®¡CSV
4. ç”Ÿæˆæ±‡æ€»MarkdownæŠ¥å‘Š

è¾“å‡ºç»“æ„ï¼š
outputs/analysis/extraction_time/
â”œâ”€â”€ extraction_time_summary.md    # æ±‡æ€»æŠ¥å‘Š
â”œâ”€â”€ deepseek/
â”‚   â””â”€â”€ paper_time_stats.csv      # DeepSeekæ¯ç¯‡è®ºæ–‡çš„æ—¶é—´ç»Ÿè®¡
â”œâ”€â”€ gemini/
â”‚   â””â”€â”€ paper_time_stats.csv
â””â”€â”€ kimi/
    â””â”€â”€ paper_time_stats.csv
"""

import json
import os
from pathlib import Path
import argparse
from datetime import datetime
import pandas as pd
from typing import Dict, List

# ------------------------------
# é…ç½®è·¯å¾„
# ------------------------------
BASE_DIR = Path("E:/langchain")

# å®éªŒé€‰æ‹©ï¼šå‘½ä»¤è¡Œä¼˜å…ˆï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼Œé»˜è®¤ exp02
_parser = argparse.ArgumentParser(add_help=False)
_parser.add_argument("--exp", dest="exp_id", choices=["exp02", "exp03"], default=None)
_parser.add_argument("--exp02", dest="exp02", action="store_true")
_parser.add_argument("--exp03", dest="exp03", action="store_true")
_parser.add_argument("--03", dest="exp03_short", action="store_true")
_args, _unknown = _parser.parse_known_args()
_env_exp = os.getenv("EXP_ID")
if _args.exp_id in {"exp02", "exp03"}:
    EXP_ID = _args.exp_id
elif _args.exp03 or _args.exp03_short:
    EXP_ID = "exp03"
elif _args.exp02:
    EXP_ID = "exp02"
elif _env_exp in {"exp02", "exp03"}:
    EXP_ID = _env_exp
else:
    EXP_ID = "exp02"

LOGS_DIR = BASE_DIR / f"outputs/logs/{EXP_ID}"
OUTPUT_DIR = BASE_DIR / f"outputs/analysis/extraction_time/{EXP_ID}"

# æ¨¡å‹æ—¥å¿—ç›®å½•
DEEPSEEK_LOG = LOGS_DIR / "deepseek"
GEMINI_LOG = LOGS_DIR / "gemini"
KIMI_LOG = LOGS_DIR / "kimi"

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ------------------------------
# æ ¸å¿ƒå‡½æ•°
# ------------------------------

def find_latest_log(log_dir: Path) -> Path:
    """æ‰¾åˆ°æŒ‡å®šç›®å½•ä¸‹æœ€æ–°çš„extraction_logæ–‡ä»¶"""
    log_files = list(log_dir.glob("extraction_log_*.json"))
    if not log_files:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶: {log_dir}")
    
    # æŒ‰æ–‡ä»¶åæ’åºï¼Œå–æœ€æ–°çš„
    latest_log = sorted(log_files, reverse=True)[0]
    return latest_log

def extract_paper_name(paper_path: str) -> str:
    """ä»å®Œæ•´è·¯å¾„ä¸­æå–è®ºæ–‡åç§°"""
    # ä¾‹å¦‚: "priority/åŸºäºXXX.md" -> "åŸºäºXXX"
    filename = Path(paper_path).stem
    return filename

def analyze_log_file(log_file: Path, model_name: str) -> Dict:
    """åˆ†æå•ä¸ªæ—¥å¿—æ–‡ä»¶ï¼Œæå–æ—¶é—´ä¿¡æ¯"""
    print(f"\nğŸ“Š åˆ†æ {model_name} æ—¥å¿—æ–‡ä»¶: {log_file.name}")
    
    with open(log_file, 'r', encoding='utf-8') as f:
        log_data = json.load(f)
    
    # æå–è®ºæ–‡çº§åˆ«çš„æ—¶é—´ç»Ÿè®¡
    paper_stats = []
    for entry in log_data.get("logs", []):
        if entry.get("success", False):
            paper_stats.append({
                "paper": extract_paper_name(entry["paper"]),
                "duration_seconds": round(entry["duration_seconds"], 2),
                "duration_minutes": round(entry["duration_seconds"] / 60, 2),
                "entity_count": entry.get("entity_count", 0),
                "relation_count": entry.get("relation_count", 0),
                "prompt_tokens": entry.get("prompt_tokens", 0),
                "completion_tokens": entry.get("completion_tokens", 0),
                "total_tokens": entry.get("total_tokens", 0)
            })
    
    # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
    total_papers = len(paper_stats)
    total_time = sum(p["duration_seconds"] for p in paper_stats)
    avg_time = total_time / total_papers if total_papers > 0 else 0
    min_time = min((p["duration_seconds"] for p in paper_stats), default=0)
    max_time = max((p["duration_seconds"] for p in paper_stats), default=0)
    
    total_entities = sum(p["entity_count"] for p in paper_stats)
    total_relations = sum(p["relation_count"] for p in paper_stats)
    total_tokens_used = sum(p["total_tokens"] for p in paper_stats)
    
    print(f"   - æˆåŠŸè®ºæ–‡æ•°: {total_papers}")
    print(f"   - æ€»è€—æ—¶: {round(total_time / 60, 2)} åˆ†é’Ÿ")
    print(f"   - å¹³å‡è€—æ—¶: {round(avg_time, 2)} ç§’/ç¯‡")
    
    return {
        "model": model_name,
        "total_papers": total_papers,
        "total_time_seconds": round(total_time, 2),
        "total_time_minutes": round(total_time / 60, 2),
        "avg_time_seconds": round(avg_time, 2),
        "min_time_seconds": round(min_time, 2),
        "max_time_seconds": round(max_time, 2),
        "total_entities": total_entities,
        "total_relations": total_relations,
        "total_tokens": total_tokens_used,
        "avg_tokens_per_paper": round(total_tokens_used / total_papers, 0) if total_papers > 0 else 0,
        "paper_stats": paper_stats
    }

# ------------------------------
# ä¸»ç¨‹åº
# ------------------------------
def main():
    print("=" * 80)
    print("â±ï¸ RAG æ¨¡å‹æŠ½å–æ—¶é—´ç»Ÿè®¡åˆ†æ")
    print("=" * 80)
    print(f"å®éªŒ: {EXP_ID}")
    print(f"æ—¥å¿—ç›®å½•: {LOGS_DIR}")
    print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    
    # åˆ†æä¸‰ä¸ªæ¨¡å‹
    models_config = [
        ("DeepSeek", DEEPSEEK_LOG),
        ("Gemini", GEMINI_LOG),
        ("Kimi", KIMI_LOG)
    ]
    
    all_results = []
    
    for model_name, log_dir in models_config:
        try:
            # æ‰¾åˆ°æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
            latest_log = find_latest_log(log_dir)
            result = analyze_log_file(latest_log, model_name)
            all_results.append(result)
            
            # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå­ç›®å½•å¹¶ä¿å­˜è®ºæ–‡æ—¶é—´ç»Ÿè®¡
            model_output_dir = OUTPUT_DIR / model_name.lower()
            os.makedirs(model_output_dir, exist_ok=True)
            
            paper_stats_df = pd.DataFrame(result["paper_stats"])
            paper_stats_file = model_output_dir / "paper_time_stats.csv"
            paper_stats_df.to_csv(paper_stats_file, index=False, encoding='utf-8-sig')
            print(f"   âœ… å·²ä¿å­˜: {paper_stats_file}")
            
        except FileNotFoundError as e:
            print(f"   âš ï¸ {e}")
            continue
    
    if not all_results:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•æ—¥å¿—æ–‡ä»¶ï¼Œé€€å‡ºåˆ†æ")
        return
    
    # ------------------------------
    # ç”Ÿæˆæ±‡æ€»è¡¨æ ¼
    # ------------------------------
    print("\n" + "=" * 80)
    print("ğŸ“‹ æ¨¡å‹å¯¹æ¯”æ±‡æ€»")
    print("=" * 80)
    
    summary_df = pd.DataFrame([
        {
            "æ¨¡å‹": r["model"],
            "è®ºæ–‡æ•°": r["total_papers"],
            "æ€»è€—æ—¶(åˆ†é’Ÿ)": r["total_time_minutes"],
            "å¹³å‡è€—æ—¶(ç§’)": r["avg_time_seconds"],
            "æœ€çŸ­è€—æ—¶(ç§’)": r["min_time_seconds"],
            "æœ€é•¿è€—æ—¶(ç§’)": r["max_time_seconds"],
            "æ€»Tokenæ•°": r["total_tokens"],
            "å¹³å‡Tokenæ•°": int(r["avg_tokens_per_paper"])
        }
        for r in all_results
    ])
    
    print(summary_df.to_string(index=False))
    
    # ------------------------------
    # ç”Ÿæˆæ±‡æ€» Markdown æŠ¥å‘Š
    # ------------------------------
    report_file = OUTPUT_DIR / "extraction_time_summary.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# RAG æ¨¡å‹æŠ½å–æ—¶é—´ç»Ÿè®¡æŠ¥å‘Š\n\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("## 1. æ¨¡å‹æ—¶é—´å¯¹æ¯”æ±‡æ€»\n\n")
        # ç”Ÿæˆ Markdown è¡¨æ ¼
        headers = summary_df.columns.tolist()
        f.write("| " + " | ".join(headers) + " |\n")
        f.write("|" + "|".join(["---"] * len(headers)) + "|\n")
        for _, row in summary_df.iterrows():
            f.write("| " + " | ".join(str(v) for v in row.values) + " |\n")
        f.write("\n")
        
        f.write("## 2. å…³é”®å‘ç°\n\n")
        
        fastest_avg = min(all_results, key=lambda x: x["avg_time_seconds"])
        slowest_avg = max(all_results, key=lambda x: x["avg_time_seconds"])
        most_efficient = min(all_results, key=lambda x: x["total_time_minutes"])
        most_tokens = max(all_results, key=lambda x: x["avg_tokens_per_paper"])
        
        f.write(f"- **æœ€å¿«å¹³å‡é€Ÿåº¦**: {fastest_avg['model']} ({fastest_avg['avg_time_seconds']} ç§’/ç¯‡)\n")
        f.write(f"- **æœ€æ…¢å¹³å‡é€Ÿåº¦**: {slowest_avg['model']} ({slowest_avg['avg_time_seconds']} ç§’/ç¯‡)\n")
        f.write(f"- **æ€»æ—¶é—´æœ€çŸ­**: {most_efficient['model']} ({most_efficient['total_time_minutes']} åˆ†é’Ÿ)\n")
        f.write(f"- **æœ€å¤šTokenæ¶ˆè€—**: {most_tokens['model']} (å¹³å‡ {int(most_tokens['avg_tokens_per_paper'])} tokens/ç¯‡)\n\n")
        
        # è®¡ç®—é€Ÿåº¦å¯¹æ¯”
        speed_ratio = slowest_avg['avg_time_seconds'] / fastest_avg['avg_time_seconds']
        f.write(f"- **é€Ÿåº¦å·®å¼‚**: {slowest_avg['model']} æ¯” {fastest_avg['model']} æ…¢ {speed_ratio:.2f} å€\n\n")
        
        f.write("## 3. å„æ¨¡å‹è¯¦ç»†æ•°æ®\n\n")
        
        for r in all_results:
            model_name = r['model']
            f.write(f"### {model_name}\n\n")
            f.write(f"- è®ºæ–‡æ•°: {r['total_papers']}\n")
            f.write(f"- æ€»è€—æ—¶: {r['total_time_minutes']} åˆ†é’Ÿ ({r['total_time_seconds']} ç§’)\n")
            f.write(f"- å¹³å‡è€—æ—¶: {r['avg_time_seconds']} ç§’/ç¯‡\n")
            f.write(f"- æœ€çŸ­è€—æ—¶: {r['min_time_seconds']} ç§’\n")
            f.write(f"- æœ€é•¿è€—æ—¶: {r['max_time_seconds']} ç§’\n")
            f.write(f"- æ€»Tokenæ¶ˆè€—: {r['total_tokens']:,}\n")
            f.write(f"- å¹³å‡Tokenæ¶ˆè€—: {int(r['avg_tokens_per_paper']):,} tokens/ç¯‡\n")
            f.write(f"- æŠ½å–æ•ˆç‡: {round(r['total_entities'] + r['total_relations'], 0) / r['total_time_seconds']:.2f} ä¸ªçŸ¥è¯†å…ƒç´ /ç§’\n")
            f.write(f"- è¯¦ç»†æ•°æ®: `{model_name.lower()}/paper_time_stats.csv`\n\n")
        
        f.write("## 4. æ–‡ä»¶è¯´æ˜\n\n")
        f.write("```\n")
        f.write("extraction_time/\n")
        f.write("â”œâ”€â”€ extraction_time_summary.md    # æœ¬æ–‡ä»¶ï¼ˆæ±‡æ€»æŠ¥å‘Šï¼‰\n")
        f.write("â”œâ”€â”€ deepseek/\n")
        f.write("â”‚   â””â”€â”€ paper_time_stats.csv     # DeepSeek æ¯ç¯‡è®ºæ–‡çš„æ—¶é—´ç»Ÿè®¡\n")
        f.write("â”œâ”€â”€ gemini/\n")
        f.write("â”‚   â””â”€â”€ paper_time_stats.csv     # Gemini æ¯ç¯‡è®ºæ–‡çš„æ—¶é—´ç»Ÿè®¡\n")
        f.write("â””â”€â”€ kimi/\n")
        f.write("    â””â”€â”€ paper_time_stats.csv     # Kimi æ¯ç¯‡è®ºæ–‡çš„æ—¶é—´ç»Ÿè®¡\n")
        f.write("```\n\n")
        
        f.write("## 5. CSV æ–‡ä»¶åˆ—è¯´æ˜\n\n")
        f.write("- **paper**: è®ºæ–‡åç§°\n")
        f.write("- **duration_seconds**: æŠ½å–è€—æ—¶ï¼ˆç§’ï¼‰\n")
        f.write("- **duration_minutes**: æŠ½å–è€—æ—¶ï¼ˆåˆ†é’Ÿï¼‰\n")
        f.write("- **entity_count**: å®ä½“æ•°é‡\n")
        f.write("- **relation_count**: å…³ç³»æ•°é‡\n")
        f.write("- **prompt_tokens**: Prompt Tokenæ•°\n")
        f.write("- **completion_tokens**: ç”ŸæˆTokenæ•°\n")
        f.write("- **total_tokens**: æ€»Tokenæ•°\n\n")
        
        f.write("## 6. æ€§èƒ½åˆ†æ\n\n")
        
        # æ—¶é—´æ•ˆç‡æ’å
        time_ranking = sorted(all_results, key=lambda x: x["avg_time_seconds"])
        f.write("### å¹³å‡é€Ÿåº¦æ’åï¼ˆä»å¿«åˆ°æ…¢ï¼‰\n\n")
        for rank, r in enumerate(time_ranking, 1):
            f.write(f"{rank}. **{r['model']}**: {r['avg_time_seconds']} ç§’/ç¯‡\n")
        f.write("\n")
        
        # Tokenæ•ˆç‡æ’å
        token_ranking = sorted(all_results, key=lambda x: x["avg_tokens_per_paper"])
        f.write("### Tokenæ¶ˆè€—æ’åï¼ˆä»å°‘åˆ°å¤šï¼‰\n\n")
        for rank, r in enumerate(token_ranking, 1):
            f.write(f"{rank}. **{r['model']}**: {int(r['avg_tokens_per_paper']):,} tokens/ç¯‡\n")
        f.write("\n")
        
        # æŠ½å–æ•ˆç‡ï¼ˆçŸ¥è¯†å…ƒç´ /ç§’ï¼‰
        efficiency_ranking = sorted(all_results, 
                                   key=lambda x: (x['total_entities'] + x['total_relations']) / x['total_time_seconds'],
                                   reverse=True)
        f.write("### æŠ½å–æ•ˆç‡æ’åï¼ˆçŸ¥è¯†å…ƒç´ /ç§’ï¼‰\n\n")
        for rank, r in enumerate(efficiency_ranking, 1):
            efficiency = (r['total_entities'] + r['total_relations']) / r['total_time_seconds']
            f.write(f"{rank}. **{r['model']}**: {efficiency:.2f} ä¸ª/ç§’\n")
    
    print(f"\nâœ… æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    # æ‰“å°ç»Ÿè®¡äº®ç‚¹
    print("\n" + "=" * 80)
    print("ğŸ¯ ç»Ÿè®¡äº®ç‚¹")
    print("=" * 80)
    
    time_ranking = sorted(all_results, key=lambda x: x["avg_time_seconds"])
    
    print("\nå¹³å‡é€Ÿåº¦æ’åï¼ˆå¿«â†’æ…¢ï¼‰:")
    for rank, r in enumerate(time_ranking, 1):
        print(f"  {rank}. {r['model']}: {r['avg_time_seconds']} ç§’/ç¯‡")
    
    print("\nTokenæ¶ˆè€—æ’åï¼ˆå°‘â†’å¤šï¼‰:")
    token_ranking = sorted(all_results, key=lambda x: x["avg_tokens_per_paper"])
    for rank, r in enumerate(token_ranking, 1):
        print(f"  {rank}. {r['model']}: {int(r['avg_tokens_per_paper']):,} tokens/ç¯‡")
    
    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆ!")
    print("=" * 80)
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"   - æ±‡æ€»æŠ¥å‘Š: extraction_time_summary.md")
    print(f"   - DeepSeekç»Ÿè®¡: deepseek/paper_time_stats.csv")
    print(f"   - Geminiç»Ÿè®¡: gemini/paper_time_stats.csv")
    print(f"   - Kimiç»Ÿè®¡: kimi/paper_time_stats.csv")

if __name__ == "__main__":
    main()
